{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://www.auth.gr/sites/default/files/banner-horizontal-282x100.png)\n",
    "# Advanced Topics in Machine Learning - Assignment 2 - Part Î‘\n",
    "\n",
    "\n",
    "## Class Imbalanced Dataset\n",
    "\n",
    "#### Useful library documentation, references, and resources used on Assignment:\n",
    "\n",
    "* Scikit-learn ML library (aka *sklearn*): <https://scikit-learn.org/stable/documentation.html>\n",
    "* Scikit-learn Multi-Label Classification : <https://github.com/scikit-multilearn/scikit-multilearn>\n",
    "* Logistic Reggresion Classifier: <https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wqbhrp28kt0D"
   },
   "source": [
    "#### Instructions about Dataset:\n",
    "In order to run the whole script you have first to download the dataset from the following link. \n",
    "* Delicious Dataset : <https://github.com/hsoleimani/MLTM/tree/master/Data>\n",
    "\n",
    "After downloading it place it in same folder with the project and name it raw_data or wherever you want and be sure to change the path given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Read the files and clean them\n",
    "\n",
    "def process_raw_data(data_fnames, labels_fnames):\n",
    "    \n",
    "    # Process Data files\n",
    "    clean_files = []\n",
    "    for datafile in data_fnames:\n",
    "     \n",
    "    # Read file from disc\n",
    "        file = open(datafile).readlines()\n",
    "    \n",
    "    # Each file is a list of docs structure to hold cleaned docs\n",
    "      \n",
    "        clean_doc = []\n",
    "        for doc in file:\n",
    "           \n",
    "        # Remove <##> patterns\n",
    "            \n",
    "            doc = re.sub('<[0-9]+>','',doc).strip()\n",
    "        \n",
    "        # Remove multiple spaces\n",
    "        \n",
    "            doc = re.sub('\\s+',' ',doc).strip()\n",
    "            clean_doc.append(doc)\n",
    "        clean_files.append(clean_doc)\n",
    "    del file, clean_doc, \n",
    "    \n",
    "    # Datasets to return\n",
    "    \n",
    "    train_data = clean_files[0]\n",
    "    train_labels = pd.read_csv(labels_fnames[0], delimiter = ' ', header = None)\n",
    "    test_data_total = clean_files[1]\n",
    "    test_labels_total = pd.read_csv(labels_fnames[1], delimiter = ' ', header = None)\n",
    "    \n",
    "    return(train_data,train_labels,test_data_total,test_labels_total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the dataset in training and testing set according to the given files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filenames of files holding the data\n",
    "\n",
    "data_filenames = [\n",
    "        'raw_data/train-data.dat',\n",
    "        'raw_data/test-data.dat'\n",
    "        ]\n",
    "\n",
    "# Filenames of files holding the labels\n",
    "\n",
    "labels_filenames = [\n",
    "            'raw_data/train-label.dat',\n",
    "            'raw_data/test-label.dat'\n",
    "            ]\n",
    "\n",
    "# Process raw data to create necessary train and test data sets\n",
    "\n",
    "X_train, y_train, X_test, y_test = process_raw_data(data_filenames, labels_filenames)\n",
    "\n",
    "# Total accuracy results for all trained classifiers\n",
    "\n",
    "total_results = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine Labels' Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  18  \\\n",
       "0   1   0   1   1   1   0   0   0   0   0   0   0   1   0   0   0   0   0   0   \n",
       "1   0   0   1   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   \n",
       "2   1   0   0   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   \n",
       "3   1   0   0   0   0   0   0   1   1   1   0   0   1   0   0   0   0   0   0   \n",
       "4   1   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "   19  \n",
       "0   0  \n",
       "1   0  \n",
       "2   0  \n",
       "3   0  \n",
       "4   0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples assigned to label 1: 2050 (24.8%)\n",
      "Train samples assigned to label 2: 479 (5.8%)\n",
      "Train samples assigned to label 3: 3181 (38.6%)\n",
      "Train samples assigned to label 4: 799 (9.7%)\n",
      "Train samples assigned to label 5: 2203 (26.7%)\n",
      "Train samples assigned to label 6: 1211 (14.7%)\n",
      "Train samples assigned to label 7: 1471 (17.8%)\n",
      "Train samples assigned to label 8: 2221 (26.9%)\n",
      "Train samples assigned to label 9: 1559 (18.9%)\n",
      "Train samples assigned to label 10: 1004 (12.2%)\n",
      "Train samples assigned to label 11: 1034 (12.5%)\n",
      "Train samples assigned to label 12: 939 (11.4%)\n",
      "Train samples assigned to label 13: 1049 (12.7%)\n",
      "Train samples assigned to label 14: 725 (8.8%)\n",
      "Train samples assigned to label 15: 830 (10.1%)\n",
      "Train samples assigned to label 16: 898 (10.9%)\n",
      "Train samples assigned to label 17: 598 (7.2%)\n",
      "Train samples assigned to label 18: 1001 (12.1%)\n",
      "Train samples assigned to label 19: 411 (5.0%)\n",
      "Train samples assigned to label 20: 224 (2.7%)\n"
     ]
    }
   ],
   "source": [
    "total = y_train.shape[0]\n",
    "for i in range(20):\n",
    "    cur = y_train.iloc[:][i][y_train.iloc[:][i] == 1].count()\n",
    "    print('Train samples assigned to label %d: %d (%.1f%%)' %(i+1, cur, 100*cur/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "We see that although the labels are not perfectly balanced, there is no label that lacks in quantity over the others. So, we will not have problem in the training phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BINARY RELEVANCE\n",
    "\n",
    "#### Try one method to treat multi-label dataset\n",
    "There are a lot of methods to treat a multi-label problem. In this assignment we are about to choose one of them. We are going to use Binary Relevance (BR). This method learns one binary classifier for each of the 20 labels we have and then it outputs the union of their predictions. It's only disadvantage is that it doesn't consider the relationships between the labels, however the results are quite good. We will handle the dataset as a bag of words. In order to do so, we vectorize each word inside the files and we do classification using Logistic Regression. The best results seems to be at label 20 with  96% accuracy. After presenting the accuracy for each label we use the mean accuracy to see something more general about our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training one binary classifier for each label (one against all)\n",
      "\n",
      "\tAccuracy of classifier on label 1: 0.8386\n",
      "\tAccuracy of classifier on label 2: 0.9453\n",
      "\tAccuracy of classifier on label 3: 0.6257\n",
      "\tAccuracy of classifier on label 4: 0.9350\n",
      "\tAccuracy of classifier on label 5: 0.7562\n",
      "\tAccuracy of classifier on label 6: 0.8250\n",
      "\tAccuracy of classifier on label 7: 0.7921\n",
      "\tAccuracy of classifier on label 8: 0.7401\n",
      "\tAccuracy of classifier on label 9: 0.7904\n",
      "\tAccuracy of classifier on label 10: 0.8787\n",
      "\tAccuracy of classifier on label 11: 0.8737\n",
      "\tAccuracy of classifier on label 12: 0.8740\n",
      "\tAccuracy of classifier on label 13: 0.8536\n",
      "\tAccuracy of classifier on label 14: 0.9048\n",
      "\tAccuracy of classifier on label 15: 0.9106\n",
      "\tAccuracy of classifier on label 16: 0.8775\n",
      "\tAccuracy of classifier on label 17: 0.9232\n",
      "\tAccuracy of classifier on label 18: 0.8802\n",
      "\tAccuracy of classifier on label 19: 0.9571\n",
      "\tAccuracy of classifier on label 20: 0.9686\n",
      "\n",
      "Mean accuracy on predicting each document's labels: 85.75%\n"
     ]
    }
   ],
   "source": [
    "# Vectorize independeny variables to use them in sklearn algorithms\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_v = vectorizer.fit_transform(X_train)\n",
    "X_test_v = vectorizer.transform(X_test)\n",
    "\n",
    "# Calculate classification probabilities for all samples in current pool_set\n",
    "# using standard classifier trained on initial train set\n",
    "\n",
    "clf = LogisticRegression()\n",
    "accuracies = []\n",
    "\n",
    "print('\\nTraining one binary classifier for each label (one against all)\\n')\n",
    "\n",
    "for i in range(20):\n",
    "    ytrain = y_train.iloc[:][i]\n",
    "    ytest = y_test.iloc[:][i]\n",
    "    # Trained classifier used for uncertainty sampling\n",
    "    clf.fit(X_train_v, ytrain)\n",
    "    \n",
    "    total_results[i] = clf.predict(X_test_v)\n",
    "    acc = accuracy_score(ytest, clf.predict(X_test_v))\n",
    "    \n",
    "    print('\\tAccuracy of classifier on label %d: %0.4f' %(i+1, acc))\n",
    "    \n",
    "    accuracies.append(acc)\n",
    "\n",
    "# Accuracy on predicting each document's labels\n",
    "\n",
    "total_count= []\n",
    "for i in range(len(y_test)):\n",
    "    test  = y_test.iloc[i:i+1][:]\n",
    "    pred = total_results.iloc[i:i+1][:]\n",
    "    count = 0\n",
    "    for j in range(20):\n",
    "        if(list(test.iloc[:][j])[0] == list(pred.iloc[:][j])[0]):\n",
    "            count +=1\n",
    "    total_count.append(count)\n",
    "mean_acc = 100*np.array(total_count).sum()/(20*len(total_count))\n",
    "\n",
    "print('\\nMean accuracy on predicting each document\\'s labels: %0.2f%%' %mean_acc) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical analysis of results\n",
    "After using the ground truth file to measure accuracy, we are making a statistical analysis of the results. First we are counding how many documents is each label presented to. Then we present it as a total rate of all documents. The most famous label seems to be label 3 which is assigned to 1465  documents and gives 36.8%. After finishing with that we check how many documents have one or more labels. There were 2 documents which had 10 labels and no documents with 11 labels, while most of documents had 2 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistical analysis (label based): \n",
      "\n",
      "\tLabel 1 assigned to 884 documents  (22.2%)\n",
      "\tLabel 2 assigned to 162 documents  (4.1%)\n",
      "\tLabel 3 assigned to 1465 documents  (36.8%)\n",
      "\tLabel 4 assigned to 289 documents  (7.3%)\n",
      "\tLabel 5 assigned to 983 documents  (24.7%)\n",
      "\tLabel 6 assigned to 506 documents  (12.7%)\n",
      "\tLabel 7 assigned to 562 documents  (14.1%)\n",
      "\tLabel 8 assigned to 958 documents  (24.1%)\n",
      "\tLabel 9 assigned to 660 documents  (16.6%)\n",
      "\tLabel 10 assigned to 382 documents  (9.6%)\n",
      "\tLabel 11 assigned to 422 documents  (10.6%)\n",
      "\tLabel 12 assigned to 346 documents  (8.7%)\n",
      "\tLabel 13 assigned to 384 documents  (9.6%)\n",
      "\tLabel 14 assigned to 276 documents  (6.9%)\n",
      "\tLabel 15 assigned to 300 documents  (7.5%)\n",
      "\tLabel 16 assigned to 313 documents  (7.9%)\n",
      "\tLabel 17 assigned to 209 documents  (5.2%)\n",
      "\tLabel 18 assigned to 330 documents  (8.3%)\n",
      "\tLabel 19 assigned to 120 documents  (3.0%)\n",
      "\tLabel 20 assigned to 76 documents  (1.9%)\n",
      "\n",
      "Statistical analysis (document based): \n",
      "\n",
      "\t418 documents classified to 0 labels (10.5%)\n",
      "\t818 documents classified to 1 labels (20.5%)\n",
      "\t951 documents classified to 2 labels (23.9%)\n",
      "\t866 documents classified to 3 labels (21.7%)\n",
      "\t556 documents classified to 4 labels (14.0%)\n",
      "\t232 documents classified to 5 labels (5.8%)\n",
      "\t98 documents classified to 6 labels (2.5%)\n",
      "\t25 documents classified to 7 labels (0.6%)\n",
      "\t13 documents classified to 8 labels (0.3%)\n",
      "\t3 documents classified to 9 labels (0.1%)\n",
      "\t2 documents classified to 10 labels (0.1%)\n",
      "\t1 documents classified to 11 labels (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Statistical analysis of the results\n",
    "\n",
    "print('\\nStatistical analysis (label based): \\n')\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    # The column of each label\n",
    "    \n",
    "    col = total_results.iloc[:][i]\n",
    "    \n",
    "    # Count how many times this label assigned\n",
    "\n",
    "    counts = col.sum()\n",
    "    print('\\tLabel %d assigned to %d documents  (%.1f%%)'\n",
    "          %(i+1, counts, 100*counts/len(col)))\n",
    "\n",
    "print('\\nStatistical analysis (document based): \\n')\n",
    "\n",
    "# Add an extra column holding the total number of labels each document classified to\n",
    "\n",
    "total_results['doc_#_labels']= total_results.iloc[:,:].sum(axis=1)\n",
    "distr = total_results['doc_#_labels'].value_counts()\n",
    "for i in range(20):\n",
    "    try:\n",
    "        \n",
    "        print('\\t%d documents classified to %d labels (%.1f%%)'\n",
    "              \n",
    "              %(distr[i], i, 100*distr[i]/total_results.shape[0]))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OVERAL RESULTS\n",
    "\n",
    "- All binary classifiers showed satisfactory learning outcomes regarding accuracy of the final predictions.\n",
    "- The indication of good training method is that all labels appear in the final forecast. We can even see the most rare of them.\n",
    "- The indications of the good performance, that our overall classification system had, is that the distribution of the predicting labels in test set are similar to the distribution of the labels in training set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
