{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's see some classification hypothesis evaluation functions treating equally the different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "step = 0.001\n",
    "x_axis = np.arange(step,1,step)\n",
    "y1_axis = -np.log(x_axis)\n",
    "y2_axis = -np.log(1-x_axis)\n",
    "plt.plot(x_axis,y1_axis, label = '$-log(h_{\\\\theta}(x))$')\n",
    "plt.plot(x_axis,y2_axis, label = '$-log(1-h_{\\\\theta}(x))$')\n",
    "plt.legend(loc='upper center', prop={'size': 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do cost-based evaluation. \n",
    "\n",
    "We must install the latest version of the costcla library using the following command at the command line:\n",
    "pip install git+git://github.com/albahnsen/CostSensitiveClassification.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.94      0.95      0.94        63\n",
      "      benign       0.97      0.96      0.97       108\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       171\n",
      "   macro avg       0.95      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n",
      "16\n",
      "\n",
      "[[ 60   4]\n",
      " [  3 104]]\n",
      "linear SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.92      0.97      0.95        63\n",
      "      benign       0.98      0.95      0.97       108\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       171\n",
      "   macro avg       0.95      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n",
      "13\n",
      "\n",
      "[[ 61   5]\n",
      " [  2 103]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from costcla.metrics import cost_loss\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=0)\n",
    "\n",
    "# 0 is malignant, 1 is benign\n",
    "#fp, fn, tp, tn\n",
    "fp = np.full((y_test.shape[0],1), 4)\n",
    "fn = np.full((y_test.shape[0],1), 1)\n",
    "tp = np.zeros((y_test.shape[0],1))\n",
    "tn = np.zeros((y_test.shape[0],1))\n",
    "cost_matrix = np.hstack((fp, fn, tp, tn))\n",
    "\n",
    "print(\"random forest\")\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))\n",
    "loss = cost_loss(y_test, y_pred, cost_matrix)\n",
    "print(\"%d\\n\" %loss)\n",
    "print(confusion_matrix(y_test, y_pred).T) # transpose to align with slides\n",
    "\n",
    "\n",
    "print(\"linear SVM\")\n",
    "clf = SVC(kernel='linear', probability=True, C=1).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))\n",
    "loss = cost_loss(y_test, y_pred, cost_matrix)\n",
    "print(\"%d\\n\" %loss)\n",
    "print(confusion_matrix(y_test, y_pred).T) # transpose to align with slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Minizing the expected cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no cost minimization\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.94      0.95      0.94        63\n",
      "      benign       0.97      0.96      0.97       108\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       171\n",
      "   macro avg       0.95      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n",
      "16\n",
      "\n",
      "[[ 60   4]\n",
      " [  3 104]]\n",
      "no calibration\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.79      1.00      0.88        63\n",
      "      benign       1.00      0.84      0.91       108\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       171\n",
      "   macro avg       0.89      0.92      0.90       171\n",
      "weighted avg       0.92      0.90      0.90       171\n",
      "\n",
      "17\n",
      "\n",
      "[[63 17]\n",
      " [ 0 91]]\n",
      "costcla calibration on training set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.89      0.98      0.93        63\n",
      "      benign       0.99      0.93      0.96       108\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       171\n",
      "   macro avg       0.94      0.96      0.94       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n",
      "12\n",
      "\n",
      "[[ 62   8]\n",
      " [  1 100]]\n",
      "\n",
      "sigmoid calibration\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.85      1.00      0.92        63\n",
      "      benign       1.00      0.90      0.95       108\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       171\n",
      "   macro avg       0.93      0.95      0.93       171\n",
      "weighted avg       0.95      0.94      0.94       171\n",
      "\n",
      "11\n",
      "\n",
      "[[63 11]\n",
      " [ 0 97]]\n",
      "\n",
      "isotonic calibration\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.84      1.00      0.91        63\n",
      "      benign       1.00      0.89      0.94       108\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       171\n",
      "   macro avg       0.92      0.94      0.93       171\n",
      "weighted avg       0.94      0.93      0.93       171\n",
      "\n",
      "12\n",
      "\n",
      "[[63 12]\n",
      " [ 0 96]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from costcla.models import BayesMinimumRiskClassifier\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=0)\n",
    "# 0 is malignant, 1 is benign\n",
    "#fp, fn, tp, tn\n",
    "fp = np.full((y_test.shape[0],1), 4)\n",
    "fn = np.full((y_test.shape[0],1), 1)\n",
    "tp = np.zeros((y_test.shape[0],1))\n",
    "tn = np.zeros((y_test.shape[0],1))\n",
    "cost_matrix = np.hstack((fp, fn, tp, tn))\n",
    "\n",
    "print(\"no cost minimization\")\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=100)\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "print(classification_report(y_test, pred_test, target_names=data.target_names))\n",
    "loss = cost_loss(y_test, pred_test, cost_matrix)\n",
    "print(\"%d\\n\" %loss)\n",
    "print(confusion_matrix(y_test, pred_test).T) # transpose to align with slides\n",
    "\n",
    "\n",
    "print(\"no calibration\")\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=100)\n",
    "model = clf.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "print(classification_report(y_test, pred_test, target_names=data.target_names))\n",
    "loss = cost_loss(y_test, pred_test, cost_matrix)\n",
    "print(\"%d\\n\" %loss)\n",
    "print(confusion_matrix(y_test, pred_test).T) # transpose to align with slides\n",
    "\n",
    "print(\"costcla calibration on training set\")\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=100)\n",
    "model = clf.fit(X_train, y_train)\n",
    "prob_train = model.predict_proba(X_train)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=True)\n",
    "bmr.fit(y_train, prob_train) \n",
    "prob_test = model.predict_proba(X_test)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "print(classification_report(y_test, pred_test, target_names=data.target_names))\n",
    "loss = cost_loss(y_test, pred_test, cost_matrix)\n",
    "print(\"%d\\n\" %loss)\n",
    "print(confusion_matrix(y_test, pred_test).T) # transpose to align with slides\n",
    "\n",
    "print(\"\\nsigmoid calibration\")\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=100)\n",
    "cc = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=3)\n",
    "model = cc.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "print(classification_report(y_test, pred_test, target_names=data.target_names))\n",
    "loss = cost_loss(y_test, pred_test, cost_matrix)\n",
    "print(\"%d\\n\" %loss)\n",
    "print(confusion_matrix(y_test, pred_test).T) # transpose to align with slides\n",
    "\n",
    "print(\"\\nisotonic calibration\")\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=100)\n",
    "cc = CalibratedClassifierCV(clf, method=\"isotonic\", cv=3)\n",
    "model = cc.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "print(classification_report(y_test, pred_test, target_names=data.target_names))\n",
    "loss = cost_loss(y_test, pred_test, cost_matrix)\n",
    "print(\"%d\\n\" %loss)\n",
    "print(confusion_matrix(y_test, pred_test).T) # transpose to align with slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebalancing\n",
    "pip install -U git+https://github.com/scikit-learn-contrib/imbalanced-learn.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without sampling\n",
      "Counter({1: 249, 0: 149})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.94      0.95      0.94        63\n",
      "      benign       0.97      0.96      0.97       108\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       171\n",
      "   macro avg       0.95      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n",
      "16\n",
      "\n",
      "[[ 60   4]\n",
      " [  3 104]]\n",
      "with undersampling\n",
      "Counter({0: 149, 1: 37})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.77      1.00      0.87        63\n",
      "      benign       1.00      0.82      0.90       108\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       171\n",
      "   macro avg       0.88      0.91      0.89       171\n",
      "weighted avg       0.91      0.89      0.89       171\n",
      "\n",
      "19\n",
      "\n",
      "[[63 19]\n",
      " [ 0 89]]\n",
      "with oversampling\n",
      "Counter({0: 1000, 1: 249})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\greg\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:254: UserWarning: After over-sampling, the number of samples (1000) in class 0 will be larger than the number of samples in the majority class (class #1 -> 249)\n",
      "  n_samples_majority))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.92      0.95      0.94        63\n",
      "      benign       0.97      0.95      0.96       108\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       171\n",
      "   macro avg       0.95      0.95      0.95       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n",
      "17\n",
      "\n",
      "[[ 60   5]\n",
      " [  3 103]]\n",
      "with combination\n",
      "Counter({0: 400, 1: 100})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.84      1.00      0.91        63\n",
      "      benign       1.00      0.89      0.94       108\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       171\n",
      "   macro avg       0.92      0.94      0.93       171\n",
      "weighted avg       0.94      0.93      0.93       171\n",
      "\n",
      "12\n",
      "\n",
      "[[63 12]\n",
      " [ 0 96]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\greg\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:254: UserWarning: After over-sampling, the number of samples (400) in class 0 will be larger than the number of samples in the majority class (class #0 -> 149)\n",
      "  n_samples_majority))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from costcla.metrics import cost_loss\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=0)\n",
    "\n",
    "# 0 is malignant, 1 is benign\n",
    "#fp, fn, tp, tn\n",
    "fp = np.full((y_test.shape[0],1), 4)\n",
    "fn = np.full((y_test.shape[0],1), 1)\n",
    "tp = np.zeros((y_test.shape[0],1))\n",
    "tn = np.zeros((y_test.shape[0],1))\n",
    "cost_matrix = np.hstack((fp, fn, tp, tn))\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "print(\"without sampling\")\n",
    "print(Counter(y_train))\n",
    "#0: 149, 1: 249\n",
    "\n",
    "model = clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))\n",
    "loss = cost_loss(y_test, y_pred, cost_matrix)\n",
    "print(\"%d\\n\" %loss)\n",
    "print(confusion_matrix(y_test, y_pred).T) # transpose to align with slides\n",
    "\n",
    "print(\"with undersampling\")\n",
    "sampler = RandomUnderSampler(sampling_strategy={0: 149, 1: 37}, random_state=1)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "print(Counter(y_rs))\n",
    "\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))\n",
    "loss = cost_loss(y_test, y_pred, cost_matrix)\n",
    "print(\"%d\\n\" %loss)\n",
    "print(confusion_matrix(y_test, y_pred).T) # transpose to align with slides\n",
    "\n",
    "print(\"with oversampling\")\n",
    "sampler = RandomOverSampler(sampling_strategy={0: 1000, 1: 249}, random_state=1)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "print(Counter(y_rs))\n",
    "\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))\n",
    "loss = cost_loss(y_test, y_pred, cost_matrix)\n",
    "print(\"%d\\n\" %loss)\n",
    "print(confusion_matrix(y_test, y_pred).T) # transpose to align with slides\n",
    "\n",
    "print(\"with combination\")\n",
    "sampler = RandomUnderSampler(sampling_strategy={0: 149, 1: 100}, random_state=1)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "sampler = RandomOverSampler(sampling_strategy={0: 400, 1: 100}, random_state=1)\n",
    "X_rs, y_rs = sampler.fit_sample(X_rs, y_rs)\n",
    "print(Counter(y_rs))\n",
    "\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))\n",
    "loss = cost_loss(y_test, y_pred, cost_matrix)\n",
    "print(\"%d\\n\" %loss)\n",
    "print(confusion_matrix(y_test, y_pred).T) # transpose to align with slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sample weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without weights\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.91      0.94      0.92        63\n",
      "      benign       0.96      0.94      0.95       108\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       171\n",
      "   macro avg       0.93      0.94      0.94       171\n",
      "weighted avg       0.94      0.94      0.94       171\n",
      "\n",
      "22\n",
      "\n",
      "[[ 59   6]\n",
      " [  4 102]]\n",
      "\n",
      "with weights\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.95      0.94      0.94        63\n",
      "      benign       0.96      0.97      0.97       108\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       171\n",
      "   macro avg       0.96      0.95      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n",
      "19\n",
      "\n",
      "[[ 59   3]\n",
      " [  4 105]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from costcla.metrics import cost_loss\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=0)\n",
    "\n",
    "# 0 is malignant, 1 is benign\n",
    "#fp, fn, tp, tn\n",
    "fp = np.full((y_test.shape[0],1), 4)\n",
    "fn = np.full((y_test.shape[0],1), 1)\n",
    "tp = np.zeros((y_test.shape[0],1))\n",
    "tn = np.zeros((y_test.shape[0],1))\n",
    "cost_matrix = np.hstack((fp, fn, tp, tn))\n",
    "\n",
    "print(\"without weights\")\n",
    "clf = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "#clf = SVC(kernel='linear', probability=False, C=1)\n",
    "#clf = DecisionTreeClassifier()\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, pred_test, target_names=data.target_names))\n",
    "loss = cost_loss(y_test, pred_test, cost_matrix)\n",
    "print(\"%d\\n\" %loss)\n",
    "print(confusion_matrix(y_test, pred_test).T) # transpose to align with slides\n",
    "\n",
    "print(\"\\nwith weights\")\n",
    "# now create the sample weights according to y\n",
    "weights = np.zeros(y_train.shape[0])\n",
    "weights[np.where(y_train == 1)] = 1;\n",
    "weights[np.where(y_train == 0)] = 4;\n",
    "#print(data.DESCR)\n",
    "\n",
    "model = clf.fit(X_train, y_train, weights)\n",
    "pred_test = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, pred_test, target_names=data.target_names))\n",
    "loss = cost_loss(y_test, pred_test, cost_matrix)\n",
    "print(\"%d\\n\" %loss)\n",
    "print(confusion_matrix(y_test, pred_test).T) # transpose to align with slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another probability calibration example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#data = datasets.load_breast_cancer()\n",
    "#data = datasets.load_iris()\n",
    "#data = datasets.load_digits()\n",
    "#data = fetch_mldata('datasets-UCI credit-g')\n",
    "#data = fetch_mldata('MNIST original')\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "ada = AdaBoostClassifier(base_estimator=tree.DecisionTreeClassifier(),n_estimators=100, random_state=1)\n",
    "classifiers.append([ada, \"AdaBoost-ed tree\"])\n",
    "\n",
    "ada_cal = CalibratedClassifierCV(AdaBoostClassifier(base_estimator=tree.DecisionTreeClassifier(),n_estimators=100, random_state=1), cv=2, method='isotonic')\n",
    "classifiers.append([ada_cal, \"calibrated AdaBoost-ed tree (isotonic)\"])\n",
    "\n",
    "ada_cal2 = CalibratedClassifierCV(AdaBoostClassifier(base_estimator=tree.DecisionTreeClassifier(),n_estimators=100, random_state=1), cv=2, method='sigmoid')\n",
    "classifiers.append([ada_cal2, \"calibrated AdaBoost-ed tree (sigmoid)\"])\n",
    "\n",
    "neighbors = 10;\n",
    "knn = KNeighborsClassifier(n_neighbors=neighbors)\n",
    "classifiers.append([knn, \"kNN\"])\n",
    "\n",
    "knn_cal = CalibratedClassifierCV(KNeighborsClassifier(n_neighbors=neighbors), cv=2, method='isotonic')\n",
    "classifiers.append([knn_cal, \"calibrated kNN (isotonic)\"])\n",
    "\n",
    "knn_cal2 = CalibratedClassifierCV(KNeighborsClassifier(n_neighbors=neighbors), cv=2, method='sigmoid')\n",
    "classifiers.append([knn_cal2, \"calibrated kNN (sigmoid)\"])\n",
    "\n",
    "\n",
    "for classifier, label in classifiers:\n",
    "    start = time.time()\n",
    "    scores = cross_val_score(classifier, data.data, data.target, cv=10, scoring=\"neg_log_loss\")\n",
    "    stop = time.time()\n",
    "    print(\"%20s log_loss: %0.2f (+/- %0.2f), time:%.4f\" % (label, scores.mean(), scores.std() * 2, stop - start))\n",
    "\n",
    "print()\n",
    "\n",
    "for classifier, label in classifiers:\n",
    "    start = time.time()\n",
    "    scores = cross_val_score(classifier, data.data, data.target, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "    stop = time.time()\n",
    "    print(\"%20s squared error: %0.2f (+/- %0.2f), time:%.4f\" % (label, scores.mean(), scores.std() * 2, stop - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
