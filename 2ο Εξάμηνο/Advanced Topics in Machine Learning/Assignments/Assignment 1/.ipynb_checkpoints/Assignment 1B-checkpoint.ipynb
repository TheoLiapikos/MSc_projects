{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://www.auth.gr/sites/default/files/banner-horizontal-282x100.png)\n",
    "# Advanced Topics in Machine Learning - Assignment 1 - Part B\n",
    "\n",
    "\n",
    "## Cost-Sensitive Learning\n",
    "\n",
    "#### Useful library documentation, references, and resources used on Assignment:\n",
    "\n",
    "* Statlog (Heart) Dataset: <http://archive.ics.uci.edu/ml/datasets/statlog+(heart)>\n",
    "* CostCla's Documentation: <http://albahnsen.github.io/CostSensitiveClassification/#>\n",
    "* scikit-learn ML library (aka *sklearn*): <http://scikit-learn.org/stable/documentation.html>\n",
    "* Random Forest Classifier: <https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html>\n",
    "* Linear Support Vector Classifier: <https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html>\n",
    "* Multinomial Naive Bayes Classifier: <https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html>\n",
    "* Probability Calibration of Classifiers: <https://scikit-learn.org/stable/modules/calibration.html>\n",
    "* Model evaluation: quantifying the quality of predictions: <https://scikit-learn.org/stable/modules/model_evaluation.html>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theo/.local/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/home/theo/.local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from costcla.metrics import cost_loss\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from costcla.models import BayesMinimumRiskClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import statsmodels.api as sm\n",
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn import model_selection\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import cross_validation\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download Required Dataset\n",
    "#### Use Statlog (Heart) dataset from UCI repository. Dataset consist of 4 separate data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Data from Internet\n",
    "# path_cleveland = \"http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "# path_hungary = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.hungarian.data\"\n",
    "# path_swiss = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.switzerland.data\"\n",
    "# path_venice = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.va.data\"\n",
    "\n",
    "# Various random connection problems occur flequently during dataset download\n",
    "# In this case is better to use the locally stored files (in folder 'data'):\n",
    "path_cleveland = \"data/processed.cleveland.data\"\n",
    "path_hungary = \"data/processed.hungarian.data\"\n",
    "path_swiss = \"data/processed.switzerland.data\"\n",
    "path_venice = \"data/processed.va.data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing\n",
    "## 2.1 Store data into an easy to handle DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paths_to_data = [path_cleveland, path_hungary, path_swiss, path_venice]\n",
    "# Features' Headers used in DataFrame\n",
    "columns = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \n",
    "         \"ca\", \"thal\", \"target\"]\n",
    "\n",
    "# Whole DataSet consists of 4 individual data files\n",
    "# First create a separate dataframe for each data file\n",
    "dfs = []\n",
    "for i in range(len(paths_to_data)):\n",
    "    dfs.append(pd.read_csv(paths_to_data[i], names=columns))\n",
    "\n",
    "# Then concat all 4 dataframes into a single one. Create new index\n",
    "initial_data = pd.concat(dfs, ignore_index=1)\n",
    "\n",
    "# Alternative way to create the final dataframe using a single command with lambda function\n",
    "#initial_data = pd.concat(map(lambda x: pd.read_csv(x, names=columns), paths_to_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Examine initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset contains 920 examples\n",
      "\n",
      "Initial class distribution:\n",
      "Label: 0, Counts: 411 (44.7%)\n",
      "Label: 1, Counts: 509 (55.3%)\n",
      "\n",
      "   age  sex   cp trestbps chol fbs restecg thalach exang oldpeak slope   ca  \\\n",
      "0  63  1.0  1.0      145  233   1       2     150     0     2.3     3  0.0   \n",
      "1  67  1.0  4.0      160  286   0       2     108     1     1.5     2  3.0   \n",
      "2  67  1.0  4.0      120  229   0       2     129     1     2.6     2  2.0   \n",
      "3  37  1.0  3.0      130  250   0       0     187     0     3.5     3  0.0   \n",
      "4  41  0.0  2.0      130  204   0       2     172     0     1.4     1  0.0   \n",
      "5  56  1.0  2.0      120  236   0       0     178     0     0.8     1  0.0   \n",
      "6  62  0.0  4.0      140  268   0       2     160     0     3.6     3  2.0   \n",
      "7  57  0.0  4.0      120  354   0       0     163     1     0.6     1  0.0   \n",
      "8  63  1.0  4.0      130  254   0       2     147     0     1.4     2  1.0   \n",
      "9  53  1.0  4.0      140  203   1       2     155     1     3.1     3  0.0   \n",
      "\n",
      "  thal  target  \n",
      "0  6.0       0  \n",
      "1  3.0       2  \n",
      "2  7.0       1  \n",
      "3  3.0       0  \n",
      "4  3.0       0  \n",
      "5  3.0       0  \n",
      "6  3.0       3  \n",
      "7  3.0       0  \n",
      "8  7.0       2  \n",
      "9  7.0       1  \n"
     ]
    }
   ],
   "source": [
    "# Number of Examples\n",
    "samples = initial_data.shape[0]\n",
    "print('Initial dataset contains %d examples' %samples)\n",
    "\n",
    "# Compute initial class distribution (label 0 corresponds to Class 0, all other labels used correspond to Class 1)\n",
    "class_0 = initial_data.target.value_counts().values[0]\n",
    "class_1 = samples - class_0\n",
    "print('\\nInitial class distribution:')\n",
    "print('Label: 0, Counts: %d (%.1f%s)' %(class_0, 100*class_0/samples,'%'))\n",
    "print('Label: 1, Counts: %d (%.1f%s)' %(class_1, 100*class_1/samples,'%'))\n",
    "\n",
    "print('\\n',initial_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Dealing with missing data\n",
    "#### Unfortunately a large portion of data examples contain missing data, marked with '?' symbol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>114</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160</td>\n",
       "      <td>254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>158</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>134</td>\n",
       "      <td>310</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>127</td>\n",
       "      <td>333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>122</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>?</td>\n",
       "      <td>385</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp trestbps chol fbs restecg thalach exang oldpeak slope ca  \\\n",
       "910  51  0.0  4.0      114  258   1       2      96     0       1     1  ?   \n",
       "911  62  1.0  4.0      160  254   1       1     108     1       3     2  ?   \n",
       "912  53  1.0  4.0      144  300   1       1     128     1     1.5     2  ?   \n",
       "913  62  1.0  4.0      158  170   0       1     138     1       0     ?  ?   \n",
       "914  46  1.0  4.0      134  310   0       0     126     0       0     ?  ?   \n",
       "915  54  0.0  4.0      127  333   1       1     154     0       0     ?  ?   \n",
       "916  62  1.0  1.0        ?  139   0       1       ?     ?       ?     ?  ?   \n",
       "917  55  1.0  4.0      122  223   1       1     100     0       0     ?  ?   \n",
       "918  58  1.0  4.0        ?  385   1       2       ?     ?       ?     ?  ?   \n",
       "919  62  1.0  2.0      120  254   0       2      93     1       0     ?  ?   \n",
       "\n",
       "    thal  target  \n",
       "910    ?       0  \n",
       "911    ?       4  \n",
       "912    ?       3  \n",
       "913    ?       1  \n",
       "914    3       2  \n",
       "915    ?       1  \n",
       "916    ?       0  \n",
       "917    6       2  \n",
       "918    ?       0  \n",
       "919    ?       1  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As shown below up to 2/3 of initial examples contain missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age           0\n",
      "sex           0\n",
      "cp            0\n",
      "trestbps     59\n",
      "chol         30\n",
      "fbs          90\n",
      "restecg       2\n",
      "thalach      55\n",
      "exang        55\n",
      "oldpeak      62\n",
      "slope       309\n",
      "ca          611\n",
      "thal        486\n",
      "target        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace '?' symbol with 'nan'\n",
    "initial_data.replace(\"?\", np.nan, inplace=True)\n",
    "# Show missing data count for each feature\n",
    "print(initial_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suggested practice is to delete ALL examples containing missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows with missing data\n",
    "data = initial_data.dropna(axis=0)\n",
    "data.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Correct data labels corresponding to Class 1\n",
    "#### In initial data files labels '1', '2', '3' and '4' used to denote Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>122</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>114</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>170</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>152</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132</td>\n",
       "      <td>342</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>164</td>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>150</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp trestbps chol fbs restecg thalach exang oldpeak slope   ca  \\\n",
       "279  35  1.0  2.0      122  192   0       0     174     0       0     1  0.0   \n",
       "280  61  1.0  4.0      148  203   0       0     161     0       0     1  1.0   \n",
       "281  58  1.0  4.0      114  318   0       1     140     0     4.4     3  3.0   \n",
       "282  58  0.0  4.0      170  225   1       2     146     1     2.8     2  2.0   \n",
       "283  56  1.0  2.0      130  221   0       2     163     0       0     1  0.0   \n",
       "284  56  1.0  2.0      120  240   0       0     169     0       0     3  0.0   \n",
       "285  67  1.0  3.0      152  212   0       2     150     0     0.8     2  0.0   \n",
       "286  55  0.0  2.0      132  342   0       0     166     0     1.2     1  0.0   \n",
       "287  44  1.0  4.0      120  169   0       0     144     1     2.8     3  0.0   \n",
       "288  63  1.0  4.0      140  187   0       2     144     1       4     1  2.0   \n",
       "289  63  0.0  4.0      124  197   0       0     136     1       0     2  0.0   \n",
       "290  41  1.0  2.0      120  157   0       0     182     0       0     1  0.0   \n",
       "291  59  1.0  4.0      164  176   1       2      90     0       1     2  2.0   \n",
       "292  57  0.0  4.0      140  241   0       0     123     1     0.2     2  0.0   \n",
       "293  45  1.0  1.0      110  264   0       0     132     0     1.2     2  0.0   \n",
       "294  68  1.0  4.0      144  193   1       0     141     0     3.4     2  2.0   \n",
       "295  57  1.0  4.0      130  131   0       0     115     1     1.2     2  1.0   \n",
       "296  57  0.0  2.0      130  236   0       2     174     0       0     2  1.0   \n",
       "297  47  1.0  4.0      150  226   0       0      98     1     1.5     2    0   \n",
       "298  56  1.0  4.0      120  100   0       0     120     1     1.5     2    0   \n",
       "\n",
       "    thal  target  \n",
       "279  3.0       0  \n",
       "280  7.0       2  \n",
       "281  6.0       4  \n",
       "282  6.0       2  \n",
       "283  7.0       0  \n",
       "284  3.0       0  \n",
       "285  7.0       1  \n",
       "286  3.0       0  \n",
       "287  6.0       2  \n",
       "288  7.0       2  \n",
       "289  3.0       1  \n",
       "290  3.0       0  \n",
       "291  6.0       3  \n",
       "292  7.0       1  \n",
       "293  7.0       1  \n",
       "294  7.0       2  \n",
       "295  7.0       3  \n",
       "296  3.0       1  \n",
       "297    7       1  \n",
       "298    7       1  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace all these labels with a single one ('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>122</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>114</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>170</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>152</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132</td>\n",
       "      <td>342</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>164</td>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>150</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp trestbps chol fbs restecg thalach exang oldpeak slope   ca  \\\n",
       "279  35  1.0  2.0      122  192   0       0     174     0       0     1  0.0   \n",
       "280  61  1.0  4.0      148  203   0       0     161     0       0     1  1.0   \n",
       "281  58  1.0  4.0      114  318   0       1     140     0     4.4     3  3.0   \n",
       "282  58  0.0  4.0      170  225   1       2     146     1     2.8     2  2.0   \n",
       "283  56  1.0  2.0      130  221   0       2     163     0       0     1  0.0   \n",
       "284  56  1.0  2.0      120  240   0       0     169     0       0     3  0.0   \n",
       "285  67  1.0  3.0      152  212   0       2     150     0     0.8     2  0.0   \n",
       "286  55  0.0  2.0      132  342   0       0     166     0     1.2     1  0.0   \n",
       "287  44  1.0  4.0      120  169   0       0     144     1     2.8     3  0.0   \n",
       "288  63  1.0  4.0      140  187   0       2     144     1       4     1  2.0   \n",
       "289  63  0.0  4.0      124  197   0       0     136     1       0     2  0.0   \n",
       "290  41  1.0  2.0      120  157   0       0     182     0       0     1  0.0   \n",
       "291  59  1.0  4.0      164  176   1       2      90     0       1     2  2.0   \n",
       "292  57  0.0  4.0      140  241   0       0     123     1     0.2     2  0.0   \n",
       "293  45  1.0  1.0      110  264   0       0     132     0     1.2     2  0.0   \n",
       "294  68  1.0  4.0      144  193   1       0     141     0     3.4     2  2.0   \n",
       "295  57  1.0  4.0      130  131   0       0     115     1     1.2     2  1.0   \n",
       "296  57  0.0  2.0      130  236   0       2     174     0       0     2  1.0   \n",
       "297  47  1.0  4.0      150  226   0       0      98     1     1.5     2    0   \n",
       "298  56  1.0  4.0      120  100   0       0     120     1     1.5     2    0   \n",
       "\n",
       "    thal  target  \n",
       "279  3.0       0  \n",
       "280  7.0       1  \n",
       "281  6.0       1  \n",
       "282  6.0       1  \n",
       "283  7.0       0  \n",
       "284  3.0       0  \n",
       "285  7.0       1  \n",
       "286  3.0       0  \n",
       "287  6.0       1  \n",
       "288  7.0       1  \n",
       "289  3.0       1  \n",
       "290  3.0       0  \n",
       "291  6.0       1  \n",
       "292  7.0       1  \n",
       "293  7.0       1  \n",
       "294  7.0       1  \n",
       "295  7.0       1  \n",
       "296  3.0       1  \n",
       "297    7       1  \n",
       "298    7       1  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace target labels 2,3 and 4 with 1\n",
    "data['target'].replace(to_replace=[2, 3, 4], value=1, inplace=True)\n",
    "\n",
    "data.tail(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Examine final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset contains 299 examples\n",
      "\n",
      "Final class distribution:\n",
      "Label: 0, Counts: 160 (53.5%)\n",
      "Label: 1, Counts: 139 (46.5%)\n"
     ]
    }
   ],
   "source": [
    "# Number of Examples\n",
    "samples = data.shape[0]\n",
    "print('Final dataset contains %d examples' %samples)\n",
    "\n",
    "# Distribution of target labels\n",
    "print('\\nFinal class distribution:')\n",
    "for i in range(2):\n",
    "    counts = data.target.value_counts().values[i]\n",
    "    print('Label: %1d, Counts: %d (%.1f%s)' %(i, counts, 100*counts/data.shape[0],'%'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As show above both classes are well balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Dependent and Independent variables\n",
    "X = data.drop('target', axis=1)\n",
    "y = data.target\n",
    "# Spliting Train and Test variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Create the CostMatrix\n",
    "#### Based on informations taken form: http://archive.ics.uci.edu/ml/datasets/statlog+(heart)\n",
    "#### Explanation of data labels used:\n",
    ">#### 0: absence of heart disease || 1: presence of heart disease\n",
    "#### Misclassification costs:\n",
    ">#### Misclassification cost of Class 0 (corresponds to a False Positive (fp) prediction) = 1\n",
    ">#### Misclassification cost of Class 1 (corresponds to a False Negative (fn) prediction) = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for fp, fn, tp, tn\n",
    "fp = np.full((y_test.shape[0],1), 1)\n",
    "fn = np.full((y_test.shape[0],1), 5)\n",
    "tp = np.zeros((y_test.shape[0],1))\n",
    "tn = np.zeros((y_test.shape[0],1))\n",
    "cost_matrix = np.hstack((fp, fn, tp, tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 5., 0., 0.],\n",
       "       [1., 5., 0., 0.],\n",
       "       [1., 5., 0., 0.],\n",
       "       [1., 5., 0., 0.],\n",
       "       [1., 5., 0., 0.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_matrix[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Using Cost-Sensitive Techniques\n",
    "+++++++++++++++\n",
    "#### I wil use and compare 3 different Classification Algorithms:\n",
    "- #### Random Forest Algorithm\n",
    "- #### Linear SVM Algorithm\n",
    "- #### Multinomial Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function used to print Classification results from each Algorithm used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(y_test,pred_test,target_names,cost_matrix):\n",
    "    print(classification_report(y_test, pred_test, target_names=target_names ))\n",
    "    # Compute Confusion Matrix using test set's true labels and corresponding predicted labels\n",
    "    cm = confusion_matrix(y_test, pred_test)\n",
    "    # Extract fp and fn values\n",
    "    fp = cm[0][1]\n",
    "    fn = cm[1][0]\n",
    "    total_predictions = len(y_test)\n",
    "    # Print misclassifications' data\n",
    "    print('Misclassifications:%d(%.2f%s),  fp:%d,  fn:%d' %(fp+fn,100*(fp+fn)/total_predictions,'%',fp,fn))\n",
    "    # Compute total misclassification cost using method from costcla library\n",
    "    loss = cost_loss(y_test, pred_test, cost_matrix)\n",
    "    print('Total Loss:%d\\n' %loss)\n",
    "    print('Confusion Matrix (rows:predictions, columns:true values):')\n",
    "    print(cm.T)\n",
    "    return('%d' %loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Probability Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ++++++ Theory\n",
    "#### I will execute and compare 5 variations of each Classification Algorithm:\n",
    "- #### Pure algorithm without Cost Minimization\n",
    "- #### Algorithm with Cost Minimization but no data Calibration\n",
    "- #### Algorithm with Cost Minimization using Costcla Calibration on Training data set\n",
    "- #### Algorithm with Cost Minimization using Sigmoid Calibration\n",
    "- #### Algorithm with Cost Minimization using Isotonic Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame to hold results for Probability Calibration technique\n",
    "columns = ['Classification Algorithm', 'No CM', 'CM-No Cal', 'CM-Costcla', 'CM-Sigmoid', 'CM-Isotonic']\n",
    "prdf = pd.DataFrame(columns = columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********** Random Forest (No Cost Minimization) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.82      0.84      0.83        49\n",
      "Presence of heart disease (1)       0.80      0.78      0.79        41\n",
      "\n",
      "                  avg / total       0.81      0.81      0.81        90\n",
      "\n",
      "Misclassifications:17(18.89%),  fp:8,  fn:9\n",
      "Total Loss:53\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[41  9]\n",
      " [ 8 32]]\n",
      "\n",
      "\n",
      "********** Random Forest (Cost Minimization - No Calibration) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.95      0.43      0.59        49\n",
      "Presence of heart disease (1)       0.59      0.98      0.73        41\n",
      "\n",
      "                  avg / total       0.79      0.68      0.66        90\n",
      "\n",
      "Misclassifications:29(32.22%),  fp:28,  fn:1\n",
      "Total Loss:33\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[21  1]\n",
      " [28 40]]\n",
      "\n",
      "\n",
      "********** Random Forest (Cost Minimization - Costcla Calibration on training set) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.76      0.98      0.86        49\n",
      "Presence of heart disease (1)       0.96      0.63      0.76        41\n",
      "\n",
      "                  avg / total       0.85      0.82      0.82        90\n",
      "\n",
      "Misclassifications:16(17.78%),  fp:1,  fn:15\n",
      "Total Loss:76\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[48 15]\n",
      " [ 1 26]]\n",
      "\n",
      "\n",
      "********** Random Forest (Cost Minimization - Sigmoid Calibration) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.93      0.51      0.66        49\n",
      "Presence of heart disease (1)       0.62      0.95      0.75        41\n",
      "\n",
      "                  avg / total       0.79      0.71      0.70        90\n",
      "\n",
      "Misclassifications:26(28.89%),  fp:24,  fn:2\n",
      "Total Loss:34\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[25  2]\n",
      " [24 39]]\n",
      "\n",
      "\n",
      "********** Random Forest (Cost Minimization - Isotonic Calibration) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.97      0.59      0.73        49\n",
      "Presence of heart disease (1)       0.67      0.98      0.79        41\n",
      "\n",
      "                  avg / total       0.83      0.77      0.76        90\n",
      "\n",
      "Misclassifications:21(23.33%),  fp:20,  fn:1\n",
      "Total Loss:25\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[29  1]\n",
      " [20 40]]\n"
     ]
    }
   ],
   "source": [
    "# List structure to hold results of specific algorithm\n",
    "rf = ['Random Forest']\n",
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "rs=42  # Random State\n",
    "ests=100  # Number of Estimators\n",
    "\n",
    "print('\\n\\n********** Random Forest (No Cost Minimization) **********')\n",
    "clf = RandomForestClassifier(random_state=rs, n_estimators=ests)\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "rf.append(cost)\n",
    "\n",
    "print('\\n\\n********** Random Forest (Cost Minimization - No Calibration) **********')\n",
    "clf = RandomForestClassifier(random_state=rs, n_estimators=ests)\n",
    "model = clf.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "rf.append(cost)\n",
    "\n",
    "print('\\n\\n********** Random Forest (Cost Minimization - Costcla Calibration on training set) **********')\n",
    "clf = RandomForestClassifier(random_state=rs, n_estimators=ests)\n",
    "model = clf.fit(X_train, y_train)\n",
    "prob_train = model.predict_proba(X_train)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=True)\n",
    "bmr.fit(y_train, prob_train) \n",
    "prob_test = model.predict_proba(X_test)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "rf.append(cost)\n",
    "\n",
    "print('\\n\\n********** Random Forest (Cost Minimization - Sigmoid Calibration) **********')\n",
    "clf = RandomForestClassifier(random_state=rs, n_estimators=ests)\n",
    "cc = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=3)\n",
    "model = cc.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "rf.append(cost)\n",
    "\n",
    "print('\\n\\n********** Random Forest (Cost Minimization - Isotonic Calibration) **********')\n",
    "clf = RandomForestClassifier(random_state=rs, n_estimators=ests)\n",
    "cc = CalibratedClassifierCV(clf, method=\"isotonic\", cv=3)\n",
    "model = cc.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "rf.append(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Algorithm Results (Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Algorithm</th>\n",
       "      <th>No CM</th>\n",
       "      <th>CM-No Cal</th>\n",
       "      <th>CM-Costcla</th>\n",
       "      <th>CM-Sigmoid</th>\n",
       "      <th>CM-Isotonic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>53</td>\n",
       "      <td>33</td>\n",
       "      <td>76</td>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Algorithm No CM CM-No Cal CM-Costcla CM-Sigmoid CM-Isotonic\n",
       "0            Random Forest    53        33         76         34          25"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = pd.Series(rf, index=columns)\n",
    "prdf.append(rf, ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions\n",
    "#### For Random Forest Classification Algorithm best cost results achieved by using Isotonic Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Linear SVM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********** Linear SVM (No Cost Minimization) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.82      0.92      0.87        49\n",
      "Presence of heart disease (1)       0.89      0.76      0.82        41\n",
      "\n",
      "                  avg / total       0.85      0.84      0.84        90\n",
      "\n",
      "Misclassifications:14(15.56%),  fp:4,  fn:10\n",
      "Total Loss:54\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[45 10]\n",
      " [ 4 31]]\n",
      "\n",
      "\n",
      "********** Linear SVM (Cost Minimization - No Calibration) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.93      0.57      0.71        49\n",
      "Presence of heart disease (1)       0.65      0.95      0.77        41\n",
      "\n",
      "                  avg / total       0.80      0.74      0.74        90\n",
      "\n",
      "Misclassifications:23(25.56%),  fp:21,  fn:2\n",
      "Total Loss:31\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[28  2]\n",
      " [21 39]]\n",
      "\n",
      "\n",
      "********** Linear SVM (Cost Minimization - Costcla Calibration on training set) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.90      0.71      0.80        49\n",
      "Presence of heart disease (1)       0.73      0.90      0.80        41\n",
      "\n",
      "                  avg / total       0.82      0.80      0.80        90\n",
      "\n",
      "Misclassifications:18(20.00%),  fp:14,  fn:4\n",
      "Total Loss:34\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[35  4]\n",
      " [14 37]]\n",
      "\n",
      "\n",
      "********** Linear SVM (Cost Minimization - Sigmoid Calibration) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.95      0.43      0.59        49\n",
      "Presence of heart disease (1)       0.59      0.98      0.73        41\n",
      "\n",
      "                  avg / total       0.79      0.68      0.66        90\n",
      "\n",
      "Misclassifications:29(32.22%),  fp:28,  fn:1\n",
      "Total Loss:33\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[21  1]\n",
      " [28 40]]\n",
      "\n",
      "\n",
      "********** Linear SVM (Cost Minimization - Isotonic Calibration) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.96      0.51      0.67        49\n",
      "Presence of heart disease (1)       0.62      0.98      0.76        41\n",
      "\n",
      "                  avg / total       0.81      0.72      0.71        90\n",
      "\n",
      "Misclassifications:25(27.78%),  fp:24,  fn:1\n",
      "Total Loss:29\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[25  1]\n",
      " [24 40]]\n"
     ]
    }
   ],
   "source": [
    "# List structure to hold results of specific algorithm\n",
    "lsvm = ['Linear SVM']\n",
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "\n",
    "print('\\n\\n********** Linear SVM (No Cost Minimization) **********')\n",
    "clf = SVC(kernel='linear', probability=True, C=1)\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "lsvm.append(cost)\n",
    "\n",
    "print('\\n\\n********** Linear SVM (Cost Minimization - No Calibration) **********')\n",
    "clf = SVC(kernel='linear', probability=True, C=1)\n",
    "model = clf.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "lsvm.append(cost)\n",
    "\n",
    "print('\\n\\n********** Linear SVM (Cost Minimization - Costcla Calibration on training set) **********')\n",
    "clf = SVC(kernel='linear', probability=True, C=1)\n",
    "model = clf.fit(X_train, y_train)\n",
    "prob_train = model.predict_proba(X_train)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=True)\n",
    "bmr.fit(y_train, prob_train) \n",
    "prob_test = model.predict_proba(X_test)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "lsvm.append(cost)\n",
    "\n",
    "print('\\n\\n********** Linear SVM (Cost Minimization - Sigmoid Calibration) **********')\n",
    "clf = SVC(kernel='linear', probability=True, C=1)\n",
    "cc = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=3)\n",
    "model = cc.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "lsvm.append(cost)\n",
    "\n",
    "print('\\n\\n********** Linear SVM (Cost Minimization - Isotonic Calibration) **********')\n",
    "clf = SVC(kernel='linear', probability=True, C=1)\n",
    "cc = CalibratedClassifierCV(clf, method=\"isotonic\", cv=3)\n",
    "model = cc.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "lsvm.append(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM Algorithm Results (Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Algorithm</th>\n",
       "      <th>No CM</th>\n",
       "      <th>CM-No Cal</th>\n",
       "      <th>CM-Costcla</th>\n",
       "      <th>CM-Sigmoid</th>\n",
       "      <th>CM-Isotonic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>54</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Algorithm No CM CM-No Cal CM-Costcla CM-Sigmoid CM-Isotonic\n",
       "0               Linear SVM    54        31         34         33          29"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvm = pd.Series(lsvm, index=columns)\n",
    "prdf.append(lsvm, ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "#### For Linear SVM Classification Algorithm best cost results achieved by using Isotonic Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Multinomial Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********** Multinomial Naive Bayes (No Cost Minimization) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.75      0.82      0.78        49\n",
      "Presence of heart disease (1)       0.76      0.68      0.72        41\n",
      "\n",
      "                  avg / total       0.76      0.76      0.75        90\n",
      "\n",
      "Misclassifications:22(24.44%),  fp:9,  fn:13\n",
      "Total Loss:74\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[40 13]\n",
      " [ 9 28]]\n",
      "\n",
      "\n",
      "********** Multinomial Naive Bayes (Cost Minimization - No Calibration) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.80      0.76      0.78        49\n",
      "Presence of heart disease (1)       0.73      0.78      0.75        41\n",
      "\n",
      "                  avg / total       0.77      0.77      0.77        90\n",
      "\n",
      "Misclassifications:21(23.33%),  fp:12,  fn:9\n",
      "Total Loss:57\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[37  9]\n",
      " [12 32]]\n",
      "\n",
      "\n",
      "********** Multinomial Naive Bayes (Cost Minimization - Costcla Calibration on training set) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.90      0.55      0.68        49\n",
      "Presence of heart disease (1)       0.63      0.93      0.75        41\n",
      "\n",
      "                  avg / total       0.78      0.72      0.71        90\n",
      "\n",
      "Misclassifications:25(27.78%),  fp:22,  fn:3\n",
      "Total Loss:37\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[27  3]\n",
      " [22 38]]\n",
      "\n",
      "\n",
      "********** Multinomial Naive Bayes (Cost Minimization - Sigmoid Calibration) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.00      0.00      0.00        49\n",
      "Presence of heart disease (1)       0.46      1.00      0.63        41\n",
      "\n",
      "                  avg / total       0.21      0.46      0.29        90\n",
      "\n",
      "Misclassifications:49(54.44%),  fp:49,  fn:0\n",
      "Total Loss:49\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[ 0  0]\n",
      " [49 41]]\n",
      "\n",
      "\n",
      "********** Multinomial Naive Bayes (Cost Minimization - Isotonic Calibration) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.91      0.59      0.72        49\n",
      "Presence of heart disease (1)       0.66      0.93      0.77        41\n",
      "\n",
      "                  avg / total       0.79      0.74      0.74        90\n",
      "\n",
      "Misclassifications:23(25.56%),  fp:20,  fn:3\n",
      "Total Loss:35\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[29  3]\n",
      " [20 38]]\n"
     ]
    }
   ],
   "source": [
    "# List structure to hold results of specific algorithm\n",
    "mnb = ['Multinomial Naive Bayes']\n",
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "NBalpha = 0.1\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (No Cost Minimization) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "mnb.append(cost)\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (Cost Minimization - No Calibration) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "model = clf.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "mnb.append(cost)\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (Cost Minimization - Costcla Calibration on training set) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "model = clf.fit(X_train, y_train)\n",
    "prob_train = model.predict_proba(X_train)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=True)\n",
    "bmr.fit(y_train, prob_train) \n",
    "prob_test = model.predict_proba(X_test)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "mnb.append(cost)\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (Cost Minimization - Sigmoid Calibration) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "cc = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=3)\n",
    "model = cc.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "mnb.append(cost)\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (Cost Minimization - Isotonic Calibration) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "cc = CalibratedClassifierCV(clf, method=\"isotonic\", cv=3)\n",
    "model = cc.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "mnb.append(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes Algorithm Results (Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Algorithm</th>\n",
       "      <th>No CM</th>\n",
       "      <th>CM-No Cal</th>\n",
       "      <th>CM-Costcla</th>\n",
       "      <th>CM-Sigmoid</th>\n",
       "      <th>CM-Isotonic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>74</td>\n",
       "      <td>57</td>\n",
       "      <td>37</td>\n",
       "      <td>49</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Algorithm No CM CM-No Cal CM-Costcla CM-Sigmoid CM-Isotonic\n",
       "0  Multinomial Naive Bayes    74        57         37         49          35"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = pd.Series(mnb, index=columns)\n",
    "prdf.append(mnb, ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "#### For Multinomial Naive Bayes Classification Algorithm best cost results achieved by using Isotonic Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 Probability Calibration Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Algorithm</th>\n",
       "      <th>No CM</th>\n",
       "      <th>CM-No Cal</th>\n",
       "      <th>CM-Costcla</th>\n",
       "      <th>CM-Sigmoid</th>\n",
       "      <th>CM-Isotonic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>53</td>\n",
       "      <td>33</td>\n",
       "      <td>76</td>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>54</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>74</td>\n",
       "      <td>57</td>\n",
       "      <td>37</td>\n",
       "      <td>49</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Algorithm No CM CM-No Cal CM-Costcla CM-Sigmoid CM-Isotonic\n",
       "0            Random Forest    53        33         76         34          25\n",
       "1               Linear SVM    54        31         34         33          29\n",
       "2  Multinomial Naive Bayes    74        57         37         49          35"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prdf.append([rf,lsvm,mnb], ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### According to total results from 3 Classification Algorithms, shown above, using 5 different Probability Calibration approaches, I conclude the following:\n",
    "- #### Among the 5 different Probability Calibration approaches, __Isotonic Calibration__ always delivers the best results, regardless of the Classification Algorithm used each time\n",
    "- #### Among the 3 different Classification Algorithms examined, __Random Forest__ delivers the best results\n",
    "- #### The Multinomial Naive Bayes Algorithm presents __very poor performance__ if Cost Minimization is not taken into account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Stratification (Rebalancing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Random Forest (Without Sampling) *****\n",
      "Counter({0: 111, 1: 98})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.82      0.84      0.83        49\n",
      "Presence of heart disease (1)       0.80      0.78      0.79        41\n",
      "\n",
      "                  avg / total       0.81      0.81      0.81        90\n",
      "\n",
      "Misclassifications:17(18.89%),  fp:8,  fn:9\n",
      "Total Loss:53\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[41  9]\n",
      " [ 8 32]]\n",
      "\n",
      "***** Random Forest (With Undersampling Class 0 of Training Set) *****\n",
      "Counter({1: 98, 0: 20})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.92      0.47      0.62        49\n",
      "Presence of heart disease (1)       0.60      0.95      0.74        41\n",
      "\n",
      "                  avg / total       0.77      0.69      0.67        90\n",
      "\n",
      "Misclassifications:28(31.11%),  fp:26,  fn:2\n",
      "Total Loss:36\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[23  2]\n",
      " [26 39]]\n",
      "\n",
      "***** Random Forest (With Oversampling Class 1 of Training Set) *****\n",
      "Counter({1: 555, 0: 111})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.80      0.76      0.78        49\n",
      "Presence of heart disease (1)       0.73      0.78      0.75        41\n",
      "\n",
      "                  avg / total       0.77      0.77      0.77        90\n",
      "\n",
      "Misclassifications:21(23.33%),  fp:12,  fn:9\n",
      "Total Loss:57\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[37  9]\n",
      " [12 32]]\n",
      "\n",
      "***** Random Forest (With Compination: Undersampling Class 0 & Oversampling Class 1 of Training Set) *****\n",
      "Counter({1: 400, 0: 80})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.85      0.67      0.75        49\n",
      "Presence of heart disease (1)       0.69      0.85      0.76        41\n",
      "\n",
      "                  avg / total       0.77      0.76      0.75        90\n",
      "\n",
      "Misclassifications:22(24.44%),  fp:16,  fn:6\n",
      "Total Loss:46\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[33  6]\n",
      " [16 35]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "rs=42\n",
    "ests=100\n",
    "\n",
    "print('\\n\\n********** Random Forest (Without Sampling) **********')\n",
    "clf = RandomForestClassifier(n_estimators=ests, random_state=rs)\n",
    "print(Counter(y_train))\n",
    "#0:111, 1:98\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "\n",
    "print('\\n\\n********** Random Forest (With Undersampling Class 0 of Training Set) **********')\n",
    "clf = RandomForestClassifier(n_estimators=ests, random_state=rs)\n",
    "sampler = RandomUnderSampler(sampling_strategy={0:20, 1:98}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "print(Counter(y_rs))\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "pred_test = model.predict(X_test)\n",
    "print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "\n",
    "print('\\n\\n********** Random Forest (With Oversampling Class 1 of Training Set) **********')\n",
    "clf = RandomForestClassifier(n_estimators=ests, random_state=rs)\n",
    "sampler = RandomOverSampler(sampling_strategy={0:111, 1:555}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "print(Counter(y_rs))\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "pred_test = model.predict(X_test)\n",
    "print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "\n",
    "print('\\n\\n********** Random Forest (With Compination: Undersampling Class 0 & Oversampling Class 1 of Training Set) **********')\n",
    "clf = RandomForestClassifier(n_estimators=ests, random_state=rs)\n",
    "sampler = RandomUnderSampler(sampling_strategy={0:80, 1:98}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "sampler = RandomOverSampler(sampling_strategy={0:80, 1:400}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_rs, y_rs)\n",
    "print(Counter(y_rs))\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "pred_test = model.predict(X_test)\n",
    "print_results(y_test,pred_test,target_names,cost_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Linear SVM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Linear SVM (Without Sampling) *****\n",
      "Counter({0: 111, 1: 98})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.82      0.92      0.87        49\n",
      "Presence of heart disease (1)       0.89      0.76      0.82        41\n",
      "\n",
      "                  avg / total       0.85      0.84      0.84        90\n",
      "\n",
      "Misclassifications:14(15.56%),  fp:4,  fn:10\n",
      "Total Loss:54\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[45 10]\n",
      " [ 4 31]]\n",
      "\n",
      "***** Linear SVM (With Undersampling Class 0 of Training Set) *****\n",
      "Counter({1: 98, 0: 20})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.88      0.47      0.61        49\n",
      "Presence of heart disease (1)       0.59      0.93      0.72        41\n",
      "\n",
      "                  avg / total       0.75      0.68      0.66        90\n",
      "\n",
      "Misclassifications:29(32.22%),  fp:26,  fn:3\n",
      "Total Loss:41\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[23  3]\n",
      " [26 38]]\n",
      "\n",
      "***** Linear SVM (With Oversampling Class 1 of Training Set) *****\n",
      "Counter({1: 555, 0: 111})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.93      0.51      0.66        49\n",
      "Presence of heart disease (1)       0.62      0.95      0.75        41\n",
      "\n",
      "                  avg / total       0.79      0.71      0.70        90\n",
      "\n",
      "Misclassifications:26(28.89%),  fp:24,  fn:2\n",
      "Total Loss:34\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[25  2]\n",
      " [24 39]]\n",
      "\n",
      "***** Linear SVM (With Compination: Undersampling Class 0 & Oversampling Class 1 of Training Set) *****\n",
      "Counter({1: 400, 0: 80})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.90      0.55      0.68        49\n",
      "Presence of heart disease (1)       0.63      0.93      0.75        41\n",
      "\n",
      "                  avg / total       0.78      0.72      0.71        90\n",
      "\n",
      "Misclassifications:25(27.78%),  fp:22,  fn:3\n",
      "Total Loss:37\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[27  3]\n",
      " [22 38]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "rs=42\n",
    "\n",
    "print('\\n\\n********** Linear SVM (Without Sampling) **********')\n",
    "clf = SVC(kernel='linear', probability=False, C=1)\n",
    "print(Counter(y_train))\n",
    "#0:111, 1:98\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "\n",
    "print('\\n\\n********** Linear SVM (With Undersampling Class 0 of Training Set) **********')\n",
    "clf = SVC(kernel='linear', probability=False, C=1)\n",
    "sampler = RandomUnderSampler(sampling_strategy={0:20, 1:98}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "print(Counter(y_rs))\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "pred_test = model.predict(X_test)\n",
    "print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "\n",
    "print('\\n\\n********** Linear SVM (With Oversampling Class 1 of Training Set) **********')\n",
    "clf = SVC(kernel='linear', probability=False, C=1)\n",
    "sampler = RandomOverSampler(sampling_strategy={0:111, 1:555}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "print(Counter(y_rs))\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "pred_test = model.predict(X_test)\n",
    "print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "\n",
    "print('\\n\\n********** Linear SVM (With Compination: Undersampling Class 0 & Oversampling Class 1 of Training Set) **********')\n",
    "clf = SVC(kernel='linear', probability=False, C=1)\n",
    "sampler = RandomUnderSampler(sampling_strategy={0:80, 1:98}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "sampler = RandomOverSampler(sampling_strategy={0:80, 1:400}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_rs, y_rs)\n",
    "print(Counter(y_rs))\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "pred_test = model.predict(X_test)\n",
    "print_results(y_test,pred_test,target_names,cost_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Multinomial Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Multinomial Naive Bayes (Without Sampling) *****\n",
      "Counter({0: 111, 1: 98})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.75      0.82      0.78        49\n",
      "Presence of heart disease (1)       0.76      0.68      0.72        41\n",
      "\n",
      "                  avg / total       0.76      0.76      0.75        90\n",
      "\n",
      "Misclassifications:22(24.44%),  fp:9,  fn:13\n",
      "Total Loss:74\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[40 13]\n",
      " [ 9 28]]\n",
      "\n",
      "***** Multinomial Naive Bayes (With Undersampling Class 0 of Training Set) *****\n",
      "Counter({1: 98, 0: 20})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.84      0.73      0.78        49\n",
      "Presence of heart disease (1)       0.72      0.83      0.77        41\n",
      "\n",
      "                  avg / total       0.79      0.78      0.78        90\n",
      "\n",
      "Misclassifications:20(22.22%),  fp:13,  fn:7\n",
      "Total Loss:48\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[36  7]\n",
      " [13 34]]\n",
      "\n",
      "***** Multinomial Naive Bayes (With Oversampling Class 1 of Training Set) *****\n",
      "Counter({1: 555, 0: 111})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.82      0.76      0.79        49\n",
      "Presence of heart disease (1)       0.73      0.80      0.77        41\n",
      "\n",
      "                  avg / total       0.78      0.78      0.78        90\n",
      "\n",
      "Misclassifications:20(22.22%),  fp:12,  fn:8\n",
      "Total Loss:52\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[37  8]\n",
      " [12 33]]\n",
      "\n",
      "***** Multinomial Naive Bayes (With Compination: Undersampling Class 0 & Oversampling Class 1 of Training Set) *****\n",
      "Counter({1: 400, 0: 80})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.81      0.71      0.76        49\n",
      "Presence of heart disease (1)       0.70      0.80      0.75        41\n",
      "\n",
      "                  avg / total       0.76      0.76      0.76        90\n",
      "\n",
      "Misclassifications:22(24.44%),  fp:14,  fn:8\n",
      "Total Loss:54\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[35  8]\n",
      " [14 33]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "rs=42\n",
    "NBalpha = 0.1\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (Without Sampling) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "print(Counter(y_train))\n",
    "#0:111, 1:98\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (With Undersampling Class 0 of Training Set) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "sampler = RandomUnderSampler(sampling_strategy={0:20, 1:98}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "print(Counter(y_rs))\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "pred_test = model.predict(X_test)\n",
    "print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (With Oversampling Class 1 of Training Set) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "sampler = RandomOverSampler(sampling_strategy={0:111, 1:555}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "print(Counter(y_rs))\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "pred_test = model.predict(X_test)\n",
    "print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (With Compination: Undersampling Class 0 & Oversampling Class 1 of Training Set) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "sampler = RandomUnderSampler(sampling_strategy={0:80, 1:98}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "sampler = RandomOverSampler(sampling_strategy={0:80, 1:400}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_rs, y_rs)\n",
    "print(Counter(y_rs))\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "pred_test = model.predict(X_test)\n",
    "print_results(y_test,pred_test,target_names,cost_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Example Weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining weights for Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create the sample weights according to y\n",
    "# misclassification cost of class 0 = 1\n",
    "# misclassification cost of class 1 = 5\n",
    "weights = np.zeros(y_train.shape[0])\n",
    "weights[np.where(y_train == 1)] = 5;\n",
    "weights[np.where(y_train == 0)] = 1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Random Forest (Without Weights) *****\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.80      0.84      0.82        49\n",
      "Presence of heart disease (1)       0.79      0.76      0.77        41\n",
      "\n",
      "                  avg / total       0.80      0.80      0.80        90\n",
      "\n",
      "Misclassifications:18(20.00%),  fp:8,  fn:10\n",
      "Total Loss:58\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[41 10]\n",
      " [ 8 31]]\n",
      "\n",
      "***** Random Forest (With Weights) *****\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.81      0.90      0.85        49\n",
      "Presence of heart disease (1)       0.86      0.76      0.81        41\n",
      "\n",
      "                  avg / total       0.84      0.83      0.83        90\n",
      "\n",
      "Misclassifications:15(16.67%),  fp:5,  fn:10\n",
      "Total Loss:55\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[44 10]\n",
      " [ 5 31]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "rs=42\n",
    "ests=150\n",
    "\n",
    "print('\\n\\n********** Random Forest (Without Weights) **********')\n",
    "clf = RandomForestClassifier(n_estimators=ests, random_state=rs)\n",
    "#clf = SVC(kernel='linear', probability=False, C=1)\n",
    "#clf = DecisionTreeClassifier()\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "\n",
    "print('\\n\\n********** Random Forest (With Weights) **********')\n",
    "clf = RandomForestClassifier(n_estimators=ests, random_state=rs)\n",
    "model = clf.fit(X_train, y_train, weights)\n",
    "pred_test = clf.predict(X_test)\n",
    "print_results(y_test,pred_test,target_names,cost_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Linear SVM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Linear SVM (Without Weights) *****\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.82      0.92      0.87        49\n",
      "Presence of heart disease (1)       0.89      0.76      0.82        41\n",
      "\n",
      "                  avg / total       0.85      0.84      0.84        90\n",
      "\n",
      "Misclassifications:14(15.56%),  fp:4,  fn:10\n",
      "Total Loss:54\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[45 10]\n",
      " [ 4 31]]\n",
      "\n",
      "***** Linear SVM (With Weights) *****\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.90      0.55      0.68        49\n",
      "Presence of heart disease (1)       0.63      0.93      0.75        41\n",
      "\n",
      "                  avg / total       0.78      0.72      0.71        90\n",
      "\n",
      "Misclassifications:25(27.78%),  fp:22,  fn:3\n",
      "Total Loss:37\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[27  3]\n",
      " [22 38]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "\n",
    "print('\\n\\n********** Linear SVM (Without Weights) **********')\n",
    "clf = SVC(kernel='linear', probability=False, C=1)\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "\n",
    "print('\\n\\n********** Linear SVM (With Weights) **********')\n",
    "clf = SVC(kernel='linear', probability=False, C=1)\n",
    "model = clf.fit(X_train, y_train, weights)\n",
    "pred_test = clf.predict(X_test)\n",
    "print_results(y_test,pred_test,target_names,cost_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Multinomial Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Multinomial Naive Bayes (Without Weights) *****\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.75      0.82      0.78        49\n",
      "Presence of heart disease (1)       0.76      0.68      0.72        41\n",
      "\n",
      "                  avg / total       0.76      0.76      0.75        90\n",
      "\n",
      "Misclassifications:22(24.44%),  fp:9,  fn:13\n",
      "Total Loss:74\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[40 13]\n",
      " [ 9 28]]\n",
      "\n",
      "***** Multinomial Naive Bayes (With Weights) *****\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.80      0.76      0.78        49\n",
      "Presence of heart disease (1)       0.73      0.78      0.75        41\n",
      "\n",
      "                  avg / total       0.77      0.77      0.77        90\n",
      "\n",
      "Misclassifications:21(23.33%),  fp:12,  fn:9\n",
      "Total Loss:57\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[37  9]\n",
      " [12 32]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "NBalpha = 0.1\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (Without Weights) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (With Weights) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "model = clf.fit(X_train, y_train, weights)\n",
    "pred_test = clf.predict(X_test)\n",
    "print_results(y_test,pred_test,target_names,cost_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
