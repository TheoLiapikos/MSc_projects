{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://www.auth.gr/sites/default/files/banner-horizontal-282x100.png)\n",
    "# Advanced Topics in Machine Learning - Assignment 1 - Part B\n",
    "\n",
    "\n",
    "## Cost-Sensitive Learning\n",
    "\n",
    "#### Useful library documentation, references, and resources used on Assignment:\n",
    "\n",
    "* Statlog (Heart) Dataset: <http://archive.ics.uci.edu/ml/datasets/statlog+(heart)>\n",
    "* CostCla's Documentation: <http://albahnsen.github.io/CostSensitiveClassification/#>\n",
    "* scikit-learn ML library (aka *sklearn*): <http://scikit-learn.org/stable/documentation.html>\n",
    "* Random Forest Classifier: <https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html>\n",
    "* Linear Support Vector Classifier: <https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html>\n",
    "* Multinomial Naive Bayes Classifier: <https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html>\n",
    "* Probability Calibration of Classifiers: <https://scikit-learn.org/stable/modules/calibration.html>\n",
    "* Model evaluation: quantifying the quality of predictions: <https://scikit-learn.org/stable/modules/model_evaluation.html>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. __Install packages - Import necessary libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install imblearn\n",
    "# pip install costcla\n",
    "## Important! costcla is incompatible with latest versions of sklearn\n",
    "# pip install scikit-learn==0.19.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theo/.local/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/home/theo/.local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from costcla.metrics import cost_loss\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from costcla.models import BayesMinimumRiskClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. __Download Required Dataset__\n",
    "#### Use Statlog (Heart) dataset from UCI repository. Dataset consist of 4 separate data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Data from Internet\n",
    "# path_cleveland = \"http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "# path_hungary = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.hungarian.data\"\n",
    "# path_swiss = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.switzerland.data\"\n",
    "# path_venice = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.va.data\"\n",
    "\n",
    "# Various random connection problems occured flequently during dataset download\n",
    "# In this case is better to use the locally stored files (in folder 'data'):\n",
    "path_cleveland = \"data/processed.cleveland.data\"\n",
    "path_hungary = \"data/processed.hungarian.data\"\n",
    "path_swiss = \"data/processed.switzerland.data\"\n",
    "path_venice = \"data/processed.va.data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. __Data Preprocessing__\n",
    "## 2.1 Store data into an easy to handle DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paths_to_data = [path_cleveland, path_hungary, path_swiss, path_venice]\n",
    "# Features' Headers used in DataFrame\n",
    "columns = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \n",
    "         \"ca\", \"thal\", \"target\"]\n",
    "\n",
    "# Whole DataSet consists of 4 individual data files\n",
    "# First create a separate dataframe for each data file\n",
    "dfs = []\n",
    "for i in range(len(paths_to_data)):\n",
    "    dfs.append(pd.read_csv(paths_to_data[i], names=columns))\n",
    "\n",
    "# Then concat all 4 dataframes into a single one. Create new index\n",
    "initial_data = pd.concat(dfs, ignore_index=1)\n",
    "\n",
    "# Alternative way to create the final dataframe using a single command with lambda function\n",
    "#initial_data = pd.concat(map(lambda x: pd.read_csv(x, names=columns), paths_to_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Examine initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exam_dataset(labels):\n",
    "    '''\n",
    "    Method that examines a given dataset and prints the number of examples and the distribution of classes\n",
    "    Parameters:\n",
    "        labels: A list or a dataframe's column containing the labels of the dataset\n",
    "    '''\n",
    "    labels = list(labels)\n",
    "    total_examples = len(labels)\n",
    "    print('Dataset contains %d examples' %total_examples)\n",
    "    # Counter() method returns results in an unsorted dictionary format.\n",
    "    # Transform results into a sorted (by first key) list of tuples and then iterate\n",
    "    distr = sorted([(key, value) for (key, value) in Counter(labels).items()])\n",
    "    print('\\nDataset\\'s label (class) distribution:')\n",
    "    for classes, examples in distr:\n",
    "        print('\\tLabel %d:  %d examples (%.1f%%)' %(classes, examples, 100*examples/total_examples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In initial dataset label 0 corresponds to Class 0, all other labels used correspond to Class 1\n",
      "Dataset contains 920 examples\n",
      "\n",
      "Dataset's label (class) distribution:\n",
      "\tLabel 0:  411 examples (44.7%)\n",
      "\tLabel 1:  265 examples (28.8%)\n",
      "\tLabel 2:  109 examples (11.8%)\n",
      "\tLabel 3:  107 examples (11.6%)\n",
      "\tLabel 4:  28 examples (3.0%)\n",
      "\n",
      "   age  sex   cp trestbps chol fbs restecg thalach exang oldpeak slope   ca  \\\n",
      "0  63  1.0  1.0      145  233   1       2     150     0     2.3     3  0.0   \n",
      "1  67  1.0  4.0      160  286   0       2     108     1     1.5     2  3.0   \n",
      "2  67  1.0  4.0      120  229   0       2     129     1     2.6     2  2.0   \n",
      "3  37  1.0  3.0      130  250   0       0     187     0     3.5     3  0.0   \n",
      "4  41  0.0  2.0      130  204   0       2     172     0     1.4     1  0.0   \n",
      "5  56  1.0  2.0      120  236   0       0     178     0     0.8     1  0.0   \n",
      "6  62  0.0  4.0      140  268   0       2     160     0     3.6     3  2.0   \n",
      "7  57  0.0  4.0      120  354   0       0     163     1     0.6     1  0.0   \n",
      "8  63  1.0  4.0      130  254   0       2     147     0     1.4     2  1.0   \n",
      "9  53  1.0  4.0      140  203   1       2     155     1     3.1     3  0.0   \n",
      "\n",
      "  thal  target  \n",
      "0  6.0       0  \n",
      "1  3.0       2  \n",
      "2  7.0       1  \n",
      "3  3.0       0  \n",
      "4  3.0       0  \n",
      "5  3.0       0  \n",
      "6  3.0       3  \n",
      "7  3.0       0  \n",
      "8  7.0       2  \n",
      "9  7.0       1  \n"
     ]
    }
   ],
   "source": [
    "print('In initial dataset label 0 corresponds to Class 0, all other labels used correspond to Class 1')\n",
    "exam_dataset(initial_data.target)\n",
    "print('\\n',initial_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Dealing with missing data\n",
    "#### Unfortunately a large portion of data examples contain missing data, marked with '?' symbol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>114</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160</td>\n",
       "      <td>254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>158</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>134</td>\n",
       "      <td>310</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>127</td>\n",
       "      <td>333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>122</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>?</td>\n",
       "      <td>385</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp trestbps chol fbs restecg thalach exang oldpeak slope ca  \\\n",
       "910  51  0.0  4.0      114  258   1       2      96     0       1     1  ?   \n",
       "911  62  1.0  4.0      160  254   1       1     108     1       3     2  ?   \n",
       "912  53  1.0  4.0      144  300   1       1     128     1     1.5     2  ?   \n",
       "913  62  1.0  4.0      158  170   0       1     138     1       0     ?  ?   \n",
       "914  46  1.0  4.0      134  310   0       0     126     0       0     ?  ?   \n",
       "915  54  0.0  4.0      127  333   1       1     154     0       0     ?  ?   \n",
       "916  62  1.0  1.0        ?  139   0       1       ?     ?       ?     ?  ?   \n",
       "917  55  1.0  4.0      122  223   1       1     100     0       0     ?  ?   \n",
       "918  58  1.0  4.0        ?  385   1       2       ?     ?       ?     ?  ?   \n",
       "919  62  1.0  2.0      120  254   0       2      93     1       0     ?  ?   \n",
       "\n",
       "    thal  target  \n",
       "910    ?       0  \n",
       "911    ?       4  \n",
       "912    ?       3  \n",
       "913    ?       1  \n",
       "914    3       2  \n",
       "915    ?       1  \n",
       "916    ?       0  \n",
       "917    6       2  \n",
       "918    ?       0  \n",
       "919    ?       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As shown below up to 2/3 of initial examples contain missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age           0\n",
      "sex           0\n",
      "cp            0\n",
      "trestbps     59\n",
      "chol         30\n",
      "fbs          90\n",
      "restecg       2\n",
      "thalach      55\n",
      "exang        55\n",
      "oldpeak      62\n",
      "slope       309\n",
      "ca          611\n",
      "thal        486\n",
      "target        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace '?' symbol with 'nan'\n",
    "initial_data.replace(\"?\", np.nan, inplace=True)\n",
    "# Show missing data count for each feature\n",
    "print(initial_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suggested practice is to delete ALL examples containing missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows with missing data\n",
    "data = initial_data.dropna(axis=0)\n",
    "data.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Correct data labels corresponding to Class 1\n",
    "#### In initial data files labels '1', '2', '3' and '4' used to denote Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>122</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>114</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>170</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>152</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132</td>\n",
       "      <td>342</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>164</td>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>150</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp trestbps chol fbs restecg thalach exang oldpeak slope   ca  \\\n",
       "279  35  1.0  2.0      122  192   0       0     174     0       0     1  0.0   \n",
       "280  61  1.0  4.0      148  203   0       0     161     0       0     1  1.0   \n",
       "281  58  1.0  4.0      114  318   0       1     140     0     4.4     3  3.0   \n",
       "282  58  0.0  4.0      170  225   1       2     146     1     2.8     2  2.0   \n",
       "283  56  1.0  2.0      130  221   0       2     163     0       0     1  0.0   \n",
       "284  56  1.0  2.0      120  240   0       0     169     0       0     3  0.0   \n",
       "285  67  1.0  3.0      152  212   0       2     150     0     0.8     2  0.0   \n",
       "286  55  0.0  2.0      132  342   0       0     166     0     1.2     1  0.0   \n",
       "287  44  1.0  4.0      120  169   0       0     144     1     2.8     3  0.0   \n",
       "288  63  1.0  4.0      140  187   0       2     144     1       4     1  2.0   \n",
       "289  63  0.0  4.0      124  197   0       0     136     1       0     2  0.0   \n",
       "290  41  1.0  2.0      120  157   0       0     182     0       0     1  0.0   \n",
       "291  59  1.0  4.0      164  176   1       2      90     0       1     2  2.0   \n",
       "292  57  0.0  4.0      140  241   0       0     123     1     0.2     2  0.0   \n",
       "293  45  1.0  1.0      110  264   0       0     132     0     1.2     2  0.0   \n",
       "294  68  1.0  4.0      144  193   1       0     141     0     3.4     2  2.0   \n",
       "295  57  1.0  4.0      130  131   0       0     115     1     1.2     2  1.0   \n",
       "296  57  0.0  2.0      130  236   0       2     174     0       0     2  1.0   \n",
       "297  47  1.0  4.0      150  226   0       0      98     1     1.5     2    0   \n",
       "298  56  1.0  4.0      120  100   0       0     120     1     1.5     2    0   \n",
       "\n",
       "    thal  target  \n",
       "279  3.0       0  \n",
       "280  7.0       2  \n",
       "281  6.0       4  \n",
       "282  6.0       2  \n",
       "283  7.0       0  \n",
       "284  3.0       0  \n",
       "285  7.0       1  \n",
       "286  3.0       0  \n",
       "287  6.0       2  \n",
       "288  7.0       2  \n",
       "289  3.0       1  \n",
       "290  3.0       0  \n",
       "291  6.0       3  \n",
       "292  7.0       1  \n",
       "293  7.0       1  \n",
       "294  7.0       2  \n",
       "295  7.0       3  \n",
       "296  3.0       1  \n",
       "297    7       1  \n",
       "298    7       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace all these labels with a single one ('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>122</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>114</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>170</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>152</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132</td>\n",
       "      <td>342</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>164</td>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>150</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp trestbps chol fbs restecg thalach exang oldpeak slope   ca  \\\n",
       "279  35  1.0  2.0      122  192   0       0     174     0       0     1  0.0   \n",
       "280  61  1.0  4.0      148  203   0       0     161     0       0     1  1.0   \n",
       "281  58  1.0  4.0      114  318   0       1     140     0     4.4     3  3.0   \n",
       "282  58  0.0  4.0      170  225   1       2     146     1     2.8     2  2.0   \n",
       "283  56  1.0  2.0      130  221   0       2     163     0       0     1  0.0   \n",
       "284  56  1.0  2.0      120  240   0       0     169     0       0     3  0.0   \n",
       "285  67  1.0  3.0      152  212   0       2     150     0     0.8     2  0.0   \n",
       "286  55  0.0  2.0      132  342   0       0     166     0     1.2     1  0.0   \n",
       "287  44  1.0  4.0      120  169   0       0     144     1     2.8     3  0.0   \n",
       "288  63  1.0  4.0      140  187   0       2     144     1       4     1  2.0   \n",
       "289  63  0.0  4.0      124  197   0       0     136     1       0     2  0.0   \n",
       "290  41  1.0  2.0      120  157   0       0     182     0       0     1  0.0   \n",
       "291  59  1.0  4.0      164  176   1       2      90     0       1     2  2.0   \n",
       "292  57  0.0  4.0      140  241   0       0     123     1     0.2     2  0.0   \n",
       "293  45  1.0  1.0      110  264   0       0     132     0     1.2     2  0.0   \n",
       "294  68  1.0  4.0      144  193   1       0     141     0     3.4     2  2.0   \n",
       "295  57  1.0  4.0      130  131   0       0     115     1     1.2     2  1.0   \n",
       "296  57  0.0  2.0      130  236   0       2     174     0       0     2  1.0   \n",
       "297  47  1.0  4.0      150  226   0       0      98     1     1.5     2    0   \n",
       "298  56  1.0  4.0      120  100   0       0     120     1     1.5     2    0   \n",
       "\n",
       "    thal  target  \n",
       "279  3.0       0  \n",
       "280  7.0       1  \n",
       "281  6.0       1  \n",
       "282  6.0       1  \n",
       "283  7.0       0  \n",
       "284  3.0       0  \n",
       "285  7.0       1  \n",
       "286  3.0       0  \n",
       "287  6.0       1  \n",
       "288  7.0       1  \n",
       "289  3.0       1  \n",
       "290  3.0       0  \n",
       "291  6.0       1  \n",
       "292  7.0       1  \n",
       "293  7.0       1  \n",
       "294  7.0       1  \n",
       "295  7.0       1  \n",
       "296  3.0       1  \n",
       "297    7       1  \n",
       "298    7       1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace target labels 2,3 and 4 with 1\n",
    "data['target'].replace(to_replace=[2, 3, 4], value=1, inplace=True)\n",
    "\n",
    "data.tail(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Examine final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 299 examples\n",
      "\n",
      "Dataset's label (class) distribution:\n",
      "\tLabel 0:  160 examples (53.5%)\n",
      "\tLabel 1:  139 examples (46.5%)\n"
     ]
    }
   ],
   "source": [
    "exam_dataset(data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As show above both classes are well balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Dependent and Independent variables\n",
    "X = data.drop('target', axis=1)\n",
    "y = data.target\n",
    "# Spliting Train and Test variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Create the CostMatrix\n",
    "#### Based on informations taken form: http://archive.ics.uci.edu/ml/datasets/statlog+(heart)\n",
    "#### Explanation of data labels used:\n",
    ">#### 0: absence of heart disease || 1: presence of heart disease\n",
    "#### Misclassification costs:\n",
    ">#### Misclassification cost of Class 0 (corresponds to a False Positive (fp) prediction) = 1\n",
    ">#### Misclassification cost of Class 1 (corresponds to a False Negative (fn) prediction) = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for fp, fn, tp, tn\n",
    "fp = np.full((y_test.shape[0],1), 1)\n",
    "fn = np.full((y_test.shape[0],1), 5)\n",
    "tp = np.zeros((y_test.shape[0],1))\n",
    "tn = np.zeros((y_test.shape[0],1))\n",
    "cost_matrix = np.hstack((fp, fn, tp, tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 5., 0., 0.],\n",
       "       [1., 5., 0., 0.],\n",
       "       [1., 5., 0., 0.],\n",
       "       [1., 5., 0., 0.],\n",
       "       [1., 5., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_matrix[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. __Using Cost-Sensitive Techniques__\n",
    "#### Τechniques that aim to convert existing cost-insensitive learning algorithms into cost-sensitive ones. They usually act by modifying the training data without altering learning algorithms themselves. In total 4 cost-sensitive techniques will be used:\n",
    "- #### Proabability Calibration\n",
    "- #### Stratification (Rebalancing)\n",
    "- #### Example Weighting\n",
    "- #### Roulette Sampling (Cost Proportionate Roulette Sampling, CPRS)\n",
    "\n",
    "#### I will apply and compare the cost-sensitive techiniques on 3 different Classification Algorithms:\n",
    "- #### Random Forest Algorithm\n",
    "- #### Linear SVM Algorithm\n",
    "- #### Multinomial Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method to print Classification results from each Algorithm used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(y_test,pred_test,target_names,cost_matrix):\n",
    "    print(classification_report(y_test, pred_test, target_names=target_names ))\n",
    "    # Compute Confusion Matrix using test set's true labels and corresponding predicted labels\n",
    "    cm = confusion_matrix(y_test, pred_test)\n",
    "    # Extract fp and fn values\n",
    "    fp = cm[0][1]\n",
    "    fn = cm[1][0]\n",
    "    total_predictions = len(y_test)\n",
    "    # Print misclassifications' data\n",
    "    print('Misclassifications:%d(%.2f%s),  fp:%d,  fn:%d' %(fp+fn,100*(fp+fn)/total_predictions,'%',fp,fn))\n",
    "    # Compute total misclassification cost using method from costcla library\n",
    "    loss = cost_loss(y_test, pred_test, cost_matrix)\n",
    "    print('Total Loss:%d\\n' %loss)\n",
    "    print('Confusion Matrix (rows:predictions, columns:true values):')\n",
    "    print(cm.T)\n",
    "    return('%d' %loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 __Probability Calibration__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This method performs callibration of probabilistic predictions performed by the classifiers (Classification Algorithms). This procedure is shown to improve Cost Minimization performance of the classifiers.\n",
    "#### I will execute and compare 5 variations of Cost minimization and Probability Calibration on each Classification Algorithm:\n",
    "- #### Pure algorithm without Cost Minimization\n",
    "- #### Algorithm with Cost Minimization but no data Calibration\n",
    "- #### Algorithm with Cost Minimization using Costcla Calibration on Training data set\n",
    "- #### Algorithm with Cost Minimization using Sigmoid Calibration (Platt Scaling)\n",
    "- #### Algorithm with Cost Minimization using Isotonic Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame to hold results for Probability Calibration techniques\n",
    "columns = ['Classification Algorithm', 'No CM', 'CM-No Cal', 'CM-Costcla', 'CM-Sigmoid', 'CM-Isotonic']\n",
    "prdf = pd.DataFrame(columns = columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********** Random Forest (No Cost Minimization) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.82      0.84      0.83        49\n",
      "Presence of heart disease (1)       0.80      0.78      0.79        41\n",
      "\n",
      "                  avg / total       0.81      0.81      0.81        90\n",
      "\n",
      "Misclassifications:17(18.89%),  fp:8,  fn:9\n",
      "Total Loss:53\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[41  9]\n",
      " [ 8 32]]\n",
      "\n",
      "\n",
      "********** Random Forest (Cost Minimization - No Calibration) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.95      0.43      0.59        49\n",
      "Presence of heart disease (1)       0.59      0.98      0.73        41\n",
      "\n",
      "                  avg / total       0.79      0.68      0.66        90\n",
      "\n",
      "Misclassifications:29(32.22%),  fp:28,  fn:1\n",
      "Total Loss:33\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[21  1]\n",
      " [28 40]]\n",
      "\n",
      "\n",
      "********** Random Forest (Cost Minimization - Costcla Calibration on training set) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.76      0.98      0.86        49\n",
      "Presence of heart disease (1)       0.96      0.63      0.76        41\n",
      "\n",
      "                  avg / total       0.85      0.82      0.82        90\n",
      "\n",
      "Misclassifications:16(17.78%),  fp:1,  fn:15\n",
      "Total Loss:76\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[48 15]\n",
      " [ 1 26]]\n",
      "\n",
      "\n",
      "********** Random Forest (Cost Minimization - Sigmoid Calibration) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.93      0.51      0.66        49\n",
      "Presence of heart disease (1)       0.62      0.95      0.75        41\n",
      "\n",
      "                  avg / total       0.79      0.71      0.70        90\n",
      "\n",
      "Misclassifications:26(28.89%),  fp:24,  fn:2\n",
      "Total Loss:34\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[25  2]\n",
      " [24 39]]\n",
      "\n",
      "\n",
      "********** Random Forest (Cost Minimization - Isotonic Calibration) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.97      0.59      0.73        49\n",
      "Presence of heart disease (1)       0.67      0.98      0.79        41\n",
      "\n",
      "                  avg / total       0.83      0.77      0.76        90\n",
      "\n",
      "Misclassifications:21(23.33%),  fp:20,  fn:1\n",
      "Total Loss:25\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[29  1]\n",
      " [20 40]]\n"
     ]
    }
   ],
   "source": [
    "# List structure to hold results of specific algorithm\n",
    "rf = ['Random Forest']\n",
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "rs=42  # Random State\n",
    "ests=100  # Number of Estimators\n",
    "\n",
    "print('\\n\\n********** Random Forest (No Cost Minimization) **********')\n",
    "clf = RandomForestClassifier(random_state=rs, n_estimators=ests)\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "rf.append(cost)\n",
    "\n",
    "print('\\n\\n********** Random Forest (Cost Minimization - No Calibration) **********')\n",
    "clf = RandomForestClassifier(random_state=rs, n_estimators=ests)\n",
    "model = clf.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "rf.append(cost)\n",
    "\n",
    "print('\\n\\n********** Random Forest (Cost Minimization - Costcla Calibration on training set) **********')\n",
    "clf = RandomForestClassifier(random_state=rs, n_estimators=ests)\n",
    "model = clf.fit(X_train, y_train)\n",
    "prob_train = model.predict_proba(X_train)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=True)\n",
    "bmr.fit(y_train, prob_train) \n",
    "prob_test = model.predict_proba(X_test)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "rf.append(cost)\n",
    "\n",
    "print('\\n\\n********** Random Forest (Cost Minimization - Sigmoid Calibration) **********')\n",
    "clf = RandomForestClassifier(random_state=rs, n_estimators=ests)\n",
    "cc = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=3)\n",
    "model = cc.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "rf.append(cost)\n",
    "\n",
    "print('\\n\\n********** Random Forest (Cost Minimization - Isotonic Calibration) **********')\n",
    "clf = RandomForestClassifier(random_state=rs, n_estimators=ests)\n",
    "cc = CalibratedClassifierCV(clf, method=\"isotonic\", cv=3)\n",
    "model = cc.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "rf.append(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Algorithm Results (Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Algorithm</th>\n",
       "      <th>No CM</th>\n",
       "      <th>CM-No Cal</th>\n",
       "      <th>CM-Costcla</th>\n",
       "      <th>CM-Sigmoid</th>\n",
       "      <th>CM-Isotonic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>53</td>\n",
       "      <td>33</td>\n",
       "      <td>76</td>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Algorithm No CM CM-No Cal CM-Costcla CM-Sigmoid CM-Isotonic\n",
       "0            Random Forest    53        33         76         34          25"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = pd.Series(rf, index=columns)\n",
    "prdf.append(rf, ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- #### Cost Minimization __significantly improves__ misclassification cost on Random Forest Classification Algorithm\n",
    "- #### From all Probability Calibration approaches only Isotonic Calibration further __significantly improves__ algorithm's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Linear SVM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********** Linear SVM (No Cost Minimization) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.82      0.92      0.87        49\n",
      "Presence of heart disease (1)       0.89      0.76      0.82        41\n",
      "\n",
      "                  avg / total       0.85      0.84      0.84        90\n",
      "\n",
      "Misclassifications:14(15.56%),  fp:4,  fn:10\n",
      "Total Loss:54\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[45 10]\n",
      " [ 4 31]]\n",
      "\n",
      "\n",
      "********** Linear SVM (Cost Minimization - No Calibration) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.96      0.53      0.68        49\n",
      "Presence of heart disease (1)       0.63      0.98      0.77        41\n",
      "\n",
      "                  avg / total       0.81      0.73      0.72        90\n",
      "\n",
      "Misclassifications:24(26.67%),  fp:23,  fn:1\n",
      "Total Loss:28\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[26  1]\n",
      " [23 40]]\n",
      "\n",
      "\n",
      "********** Linear SVM (Cost Minimization - Costcla Calibration on training set) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.90      0.71      0.80        49\n",
      "Presence of heart disease (1)       0.73      0.90      0.80        41\n",
      "\n",
      "                  avg / total       0.82      0.80      0.80        90\n",
      "\n",
      "Misclassifications:18(20.00%),  fp:14,  fn:4\n",
      "Total Loss:34\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[35  4]\n",
      " [14 37]]\n",
      "\n",
      "\n",
      "********** Linear SVM (Cost Minimization - Sigmoid Calibration) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.95      0.43      0.59        49\n",
      "Presence of heart disease (1)       0.59      0.98      0.73        41\n",
      "\n",
      "                  avg / total       0.79      0.68      0.66        90\n",
      "\n",
      "Misclassifications:29(32.22%),  fp:28,  fn:1\n",
      "Total Loss:33\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[21  1]\n",
      " [28 40]]\n",
      "\n",
      "\n",
      "********** Linear SVM (Cost Minimization - Isotonic Calibration) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.96      0.51      0.67        49\n",
      "Presence of heart disease (1)       0.62      0.98      0.76        41\n",
      "\n",
      "                  avg / total       0.81      0.72      0.71        90\n",
      "\n",
      "Misclassifications:25(27.78%),  fp:24,  fn:1\n",
      "Total Loss:29\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[25  1]\n",
      " [24 40]]\n"
     ]
    }
   ],
   "source": [
    "# List structure to hold results of specific algorithm\n",
    "lsvm = ['Linear SVM']\n",
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "\n",
    "print('\\n\\n********** Linear SVM (No Cost Minimization) **********')\n",
    "clf = SVC(kernel='linear', probability=True, C=1)\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "lsvm.append(cost)\n",
    "\n",
    "print('\\n\\n********** Linear SVM (Cost Minimization - No Calibration) **********')\n",
    "clf = SVC(kernel='linear', probability=True, C=1)\n",
    "model = clf.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "lsvm.append(cost)\n",
    "\n",
    "print('\\n\\n********** Linear SVM (Cost Minimization - Costcla Calibration on training set) **********')\n",
    "clf = SVC(kernel='linear', probability=True, C=1)\n",
    "model = clf.fit(X_train, y_train)\n",
    "prob_train = model.predict_proba(X_train)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=True)\n",
    "bmr.fit(y_train, prob_train) \n",
    "prob_test = model.predict_proba(X_test)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "lsvm.append(cost)\n",
    "\n",
    "print('\\n\\n********** Linear SVM (Cost Minimization - Sigmoid Calibration) **********')\n",
    "clf = SVC(kernel='linear', probability=True, C=1)\n",
    "cc = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=3)\n",
    "model = cc.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "lsvm.append(cost)\n",
    "\n",
    "print('\\n\\n********** Linear SVM (Cost Minimization - Isotonic Calibration) **********')\n",
    "clf = SVC(kernel='linear', probability=True, C=1)\n",
    "cc = CalibratedClassifierCV(clf, method=\"isotonic\", cv=3)\n",
    "model = cc.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "lsvm.append(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM Algorithm Results (Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Algorithm</th>\n",
       "      <th>No CM</th>\n",
       "      <th>CM-No Cal</th>\n",
       "      <th>CM-Costcla</th>\n",
       "      <th>CM-Sigmoid</th>\n",
       "      <th>CM-Isotonic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>54</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Algorithm No CM CM-No Cal CM-Costcla CM-Sigmoid CM-Isotonic\n",
       "0               Linear SVM    54        28         34         33          29"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvm = pd.Series(lsvm, index=columns)\n",
    "prdf.append(lsvm, ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- #### Cost Minimization __significantly improves__ misclassification cost on Linear SVM Classification Algorithm\n",
    "- #### From all Probability Calibration approaches only Isotonic Calibration __just slightly further improves__ algorithm's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Multinomial Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********** Multinomial Naive Bayes (No Cost Minimization) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.75      0.82      0.78        49\n",
      "Presence of heart disease (1)       0.76      0.68      0.72        41\n",
      "\n",
      "                  avg / total       0.76      0.76      0.75        90\n",
      "\n",
      "Misclassifications:22(24.44%),  fp:9,  fn:13\n",
      "Total Loss:74\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[40 13]\n",
      " [ 9 28]]\n",
      "\n",
      "\n",
      "********** Multinomial Naive Bayes (Cost Minimization - No Calibration) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.80      0.76      0.78        49\n",
      "Presence of heart disease (1)       0.73      0.78      0.75        41\n",
      "\n",
      "                  avg / total       0.77      0.77      0.77        90\n",
      "\n",
      "Misclassifications:21(23.33%),  fp:12,  fn:9\n",
      "Total Loss:57\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[37  9]\n",
      " [12 32]]\n",
      "\n",
      "\n",
      "********** Multinomial Naive Bayes (Cost Minimization - Costcla Calibration on training set) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.90      0.55      0.68        49\n",
      "Presence of heart disease (1)       0.63      0.93      0.75        41\n",
      "\n",
      "                  avg / total       0.78      0.72      0.71        90\n",
      "\n",
      "Misclassifications:25(27.78%),  fp:22,  fn:3\n",
      "Total Loss:37\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[27  3]\n",
      " [22 38]]\n",
      "\n",
      "\n",
      "********** Multinomial Naive Bayes (Cost Minimization - Sigmoid Calibration) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.00      0.00      0.00        49\n",
      "Presence of heart disease (1)       0.46      1.00      0.63        41\n",
      "\n",
      "                  avg / total       0.21      0.46      0.29        90\n",
      "\n",
      "Misclassifications:49(54.44%),  fp:49,  fn:0\n",
      "Total Loss:49\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[ 0  0]\n",
      " [49 41]]\n",
      "\n",
      "\n",
      "********** Multinomial Naive Bayes (Cost Minimization - Isotonic Calibration) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.91      0.59      0.72        49\n",
      "Presence of heart disease (1)       0.66      0.93      0.77        41\n",
      "\n",
      "                  avg / total       0.79      0.74      0.74        90\n",
      "\n",
      "Misclassifications:23(25.56%),  fp:20,  fn:3\n",
      "Total Loss:35\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[29  3]\n",
      " [20 38]]\n"
     ]
    }
   ],
   "source": [
    "# List structure to hold results of specific algorithm\n",
    "mnb = ['Multinomial Naive Bayes']\n",
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "NBalpha = 0.1\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (No Cost Minimization) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "mnb.append(cost)\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (Cost Minimization - No Calibration) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "model = clf.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "mnb.append(cost)\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (Cost Minimization - Costcla Calibration on training set) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "model = clf.fit(X_train, y_train)\n",
    "prob_train = model.predict_proba(X_train)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=True)\n",
    "bmr.fit(y_train, prob_train) \n",
    "prob_test = model.predict_proba(X_test)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "mnb.append(cost)\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (Cost Minimization - Sigmoid Calibration) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "cc = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=3)\n",
    "model = cc.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "mnb.append(cost)\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (Cost Minimization - Isotonic Calibration) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "cc = CalibratedClassifierCV(clf, method=\"isotonic\", cv=3)\n",
    "model = cc.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "mnb.append(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes Algorithm Results (Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Algorithm</th>\n",
       "      <th>No CM</th>\n",
       "      <th>CM-No Cal</th>\n",
       "      <th>CM-Costcla</th>\n",
       "      <th>CM-Sigmoid</th>\n",
       "      <th>CM-Isotonic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>74</td>\n",
       "      <td>57</td>\n",
       "      <td>37</td>\n",
       "      <td>49</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Algorithm No CM CM-No Cal CM-Costcla CM-Sigmoid CM-Isotonic\n",
       "0  Multinomial Naive Bayes    74        57         37         49          35"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = pd.Series(mnb, index=columns)\n",
    "prdf.append(mnb, ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- #### Cost Minimization __significantly improves__ misclassification cost on Multinomial Naive Bayes Classification Algorithm\n",
    "- #### __All__ Probability Calibration approaches further __significantly improve__ algorithm's performance\n",
    "- #### For Multinomial Naive Bayes Classification Algorithm best misclassification cost results achieved by using __Isotonic Calibration__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 Probability Calibration Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Algorithm</th>\n",
       "      <th>No CM</th>\n",
       "      <th>CM-No Cal</th>\n",
       "      <th>CM-Costcla</th>\n",
       "      <th>CM-Sigmoid</th>\n",
       "      <th>CM-Isotonic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>53</td>\n",
       "      <td>33</td>\n",
       "      <td>76</td>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>54</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>74</td>\n",
       "      <td>57</td>\n",
       "      <td>37</td>\n",
       "      <td>49</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Algorithm No CM CM-No Cal CM-Costcla CM-Sigmoid CM-Isotonic\n",
       "0            Random Forest    53        33         76         34          25\n",
       "1               Linear SVM    54        28         34         33          29\n",
       "2  Multinomial Naive Bayes    74        57         37         49          35"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prdf = prdf.append([rf,lsvm,mnb], ignore_index=1)\n",
    "prdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### According to the results from 3 Classification Algorithms, shown above, using 5 different Probability Calibration approaches, I conclude the following:\n",
    "- #### Cost Minimization __significantly improves__ misclassification cost on all 3 Classification Algorithms\n",
    "- #### Probability Calibration further __significantly improves__ performance on 2 out of 3 Classification Algorithms (Random Forest and Multinomial Naive Bayes) with respect to misclassification cost\n",
    "- #### Among the 5 different Probability Calibration approaches, __Isotonic Calibration__ always delivers the best results, regardless of the Classification Algorithm used each time\n",
    "- #### Among the 3 different Classification Algorithms examined, __Random Forest__ delivers the best results\n",
    "- #### The Multinomial Naive Bayes Algorithm presents __very poor performance__ if Cost Minimization is not taken into account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 __Stratification (Rebalancing)__\n",
    "#### This method changes the distribution of the training data according to their costs. In other words it modifies the training data so that the number of examples of each class is __proportional__ to the misclassification cost of the class. \n",
    "#### In the study Dataset misclassification cost of Class 0 (corresponds to a False Positive (fp) prediction) equals to 1 whereas misclassification cost of Class 1 (corresponds to a False Negative (fn) prediction) equals to 5. I need to modify the classes distribution in a way that Class 1 contains 5 times the number of examples of Class 0. Initial distribution of classes is:\n",
    ">#### Class 0: 111 examples  |  Class 1: 98 examples.\n",
    "#### There are 3 approaches to achieve the desired class distribution:\n",
    "- #### __Oversampling__ via sampling with replacement (bagging), to increase the number of examples of Class 1 to 555 while Class 0 remains to 111 examples\n",
    "- #### __Undersampling__, to decrease the number of examples of Class 0 to 20 while Class 1 remains to 98 examples\n",
    "- #### __Combination__ of above methods, to increase the number of examples of of Class 1 to 250 and at the same time to decrease the number of examples of Class 0 to 50\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame to hold results for Stratification techniques\n",
    "columns_st = ['Classification Algorithm', 'No Sampling', 'UnderSampling', 'OverSampling', 'Combination']\n",
    "stdf = pd.DataFrame(columns = columns_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********** Random Forest (Without Sampling) **********\n",
      "Counter({0: 111, 1: 98})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.82      0.84      0.83        49\n",
      "Presence of heart disease (1)       0.80      0.78      0.79        41\n",
      "\n",
      "                  avg / total       0.81      0.81      0.81        90\n",
      "\n",
      "Misclassifications:17(18.89%),  fp:8,  fn:9\n",
      "Total Loss:53\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[41  9]\n",
      " [ 8 32]]\n",
      "\n",
      "\n",
      "********** Random Forest (With Undersampling Class 0 of Training Set) **********\n",
      "Counter({1: 98, 0: 20})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.92      0.47      0.62        49\n",
      "Presence of heart disease (1)       0.60      0.95      0.74        41\n",
      "\n",
      "                  avg / total       0.77      0.69      0.67        90\n",
      "\n",
      "Misclassifications:28(31.11%),  fp:26,  fn:2\n",
      "Total Loss:36\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[23  2]\n",
      " [26 39]]\n",
      "\n",
      "\n",
      "********** Random Forest (With Oversampling Class 1 of Training Set) **********\n",
      "Counter({1: 555, 0: 111})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.80      0.76      0.78        49\n",
      "Presence of heart disease (1)       0.73      0.78      0.75        41\n",
      "\n",
      "                  avg / total       0.77      0.77      0.77        90\n",
      "\n",
      "Misclassifications:21(23.33%),  fp:12,  fn:9\n",
      "Total Loss:57\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[37  9]\n",
      " [12 32]]\n",
      "\n",
      "\n",
      "********** Random Forest (With Combination: Undersampling Class 0 & Oversampling Class 1 of Training Set) **********\n",
      "Counter({1: 250, 0: 50})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.88      0.59      0.71        49\n",
      "Presence of heart disease (1)       0.65      0.90      0.76        41\n",
      "\n",
      "                  avg / total       0.77      0.73      0.73        90\n",
      "\n",
      "Misclassifications:24(26.67%),  fp:20,  fn:4\n",
      "Total Loss:40\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[29  4]\n",
      " [20 37]]\n"
     ]
    }
   ],
   "source": [
    "# List structure to hold results of specific algorithm\n",
    "rf_st = ['Random Forest']\n",
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "rs=42  # Random State\n",
    "ests=100  # Number of Estimators\n",
    "\n",
    "print('\\n\\n********** Random Forest (Without Sampling) **********')\n",
    "clf = RandomForestClassifier(n_estimators=ests, random_state=rs)\n",
    "print(Counter(y_train))\n",
    "#0:111, 1:98\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "rf_st.append(cost)\n",
    "\n",
    "print('\\n\\n********** Random Forest (With Undersampling Class 0 of Training Set) **********')\n",
    "clf = RandomForestClassifier(n_estimators=ests, random_state=rs)\n",
    "sampler = RandomUnderSampler(sampling_strategy={0:20, 1:98}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "print(Counter(y_rs))\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "rf_st.append(cost)\n",
    "\n",
    "print('\\n\\n********** Random Forest (With Oversampling Class 1 of Training Set) **********')\n",
    "clf = RandomForestClassifier(n_estimators=ests, random_state=rs)\n",
    "sampler = RandomOverSampler(sampling_strategy={0:111, 1:555}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "print(Counter(y_rs))\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "rf_st.append(cost)\n",
    "\n",
    "print('\\n\\n********** Random Forest (With Combination: Undersampling Class 0 & Oversampling Class 1 of Training Set) **********')\n",
    "clf = RandomForestClassifier(n_estimators=ests, random_state=rs)\n",
    "sampler = RandomUnderSampler(sampling_strategy={0:50, 1:98}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "sampler = RandomOverSampler(sampling_strategy={0:50, 1:250}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_rs, y_rs)\n",
    "print(Counter(y_rs))\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "rf_st.append(cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Algorithm Results (Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Algorithm</th>\n",
       "      <th>No Sampling</th>\n",
       "      <th>UnderSampling</th>\n",
       "      <th>OverSampling</th>\n",
       "      <th>Combination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>53</td>\n",
       "      <td>36</td>\n",
       "      <td>57</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Algorithm No Sampling UnderSampling OverSampling Combination\n",
       "0            Random Forest          53            36           57          40"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_st = pd.Series(rf_st, index=columns_st)\n",
    "stdf.append(rf_st, ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- #### UnderSampling approach __significantly improves__ misclassification cost on Random Forest Classification Algorithm\n",
    "- #### OverSampling approach __doesn't affect__ algorithm's performance\n",
    "- #### Combination approach just __slightly improves__ algorithm's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Linear SVM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********** Linear SVM (Without Sampling) **********\n",
      "Counter({0: 111, 1: 98})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.82      0.92      0.87        49\n",
      "Presence of heart disease (1)       0.89      0.76      0.82        41\n",
      "\n",
      "                  avg / total       0.85      0.84      0.84        90\n",
      "\n",
      "Misclassifications:14(15.56%),  fp:4,  fn:10\n",
      "Total Loss:54\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[45 10]\n",
      " [ 4 31]]\n",
      "\n",
      "\n",
      "********** Linear SVM (With Undersampling Class 0 of Training Set) **********\n",
      "Counter({1: 98, 0: 20})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.88      0.47      0.61        49\n",
      "Presence of heart disease (1)       0.59      0.93      0.72        41\n",
      "\n",
      "                  avg / total       0.75      0.68      0.66        90\n",
      "\n",
      "Misclassifications:29(32.22%),  fp:26,  fn:3\n",
      "Total Loss:41\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[23  3]\n",
      " [26 38]]\n",
      "\n",
      "\n",
      "********** Linear SVM (With Oversampling Class 1 of Training Set) **********\n",
      "Counter({1: 555, 0: 111})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.93      0.51      0.66        49\n",
      "Presence of heart disease (1)       0.62      0.95      0.75        41\n",
      "\n",
      "                  avg / total       0.79      0.71      0.70        90\n",
      "\n",
      "Misclassifications:26(28.89%),  fp:24,  fn:2\n",
      "Total Loss:34\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[25  2]\n",
      " [24 39]]\n",
      "\n",
      "\n",
      "********** Linear SVM (With Combination: Undersampling Class 0 & Oversampling Class 1 of Training Set) **********\n",
      "Counter({1: 250, 0: 50})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.94      0.59      0.72        49\n",
      "Presence of heart disease (1)       0.66      0.95      0.78        41\n",
      "\n",
      "                  avg / total       0.81      0.76      0.75        90\n",
      "\n",
      "Misclassifications:22(24.44%),  fp:20,  fn:2\n",
      "Total Loss:30\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[29  2]\n",
      " [20 39]]\n"
     ]
    }
   ],
   "source": [
    "# List structure to hold results of specific algorithm\n",
    "lsvm_st = ['Linear SVM']\n",
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "rs=42\n",
    "\n",
    "print('\\n\\n********** Linear SVM (Without Sampling) **********')\n",
    "clf = SVC(kernel='linear', probability=False, C=1)\n",
    "print(Counter(y_train))\n",
    "#0:111, 1:98\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "lsvm_st.append(cost)\n",
    "\n",
    "print('\\n\\n********** Linear SVM (With Undersampling Class 0 of Training Set) **********')\n",
    "clf = SVC(kernel='linear', probability=False, C=1)\n",
    "sampler = RandomUnderSampler(sampling_strategy={0:20, 1:98}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "print(Counter(y_rs))\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "lsvm_st.append(cost)\n",
    "\n",
    "print('\\n\\n********** Linear SVM (With Oversampling Class 1 of Training Set) **********')\n",
    "clf = SVC(kernel='linear', probability=False, C=1)\n",
    "sampler = RandomOverSampler(sampling_strategy={0:111, 1:555}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "print(Counter(y_rs))\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "lsvm_st.append(cost)\n",
    "\n",
    "print('\\n\\n********** Linear SVM (With Combination: Undersampling Class 0 & Oversampling Class 1 of Training Set) **********')\n",
    "clf = SVC(kernel='linear', probability=False, C=1)\n",
    "sampler = RandomUnderSampler(sampling_strategy={0:50, 1:98}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "sampler = RandomOverSampler(sampling_strategy={0:50, 1:250}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_rs, y_rs)\n",
    "print(Counter(y_rs))\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "lsvm_st.append(cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM Algorithm Results (Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Algorithm</th>\n",
       "      <th>No Sampling</th>\n",
       "      <th>UnderSampling</th>\n",
       "      <th>OverSampling</th>\n",
       "      <th>Combination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>54</td>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Algorithm No Sampling UnderSampling OverSampling Combination\n",
       "0               Linear SVM          54            41           34          30"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvm_st = pd.Series(lsvm_st, index=columns_st)\n",
    "stdf.append(lsvm_st, ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- #### All 3 Stratification approaches __significantly improve__ misclassification cost on Linear SVM Classification Algorithm\n",
    "- #### OverSampling approach delivers __best results__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Multinomial Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********** Multinomial Naive Bayes (Without Sampling) **********\n",
      "Counter({0: 111, 1: 98})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.75      0.82      0.78        49\n",
      "Presence of heart disease (1)       0.76      0.68      0.72        41\n",
      "\n",
      "                  avg / total       0.76      0.76      0.75        90\n",
      "\n",
      "Misclassifications:22(24.44%),  fp:9,  fn:13\n",
      "Total Loss:74\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[40 13]\n",
      " [ 9 28]]\n",
      "\n",
      "\n",
      "********** Multinomial Naive Bayes (With Undersampling Class 0 of Training Set) **********\n",
      "Counter({1: 98, 0: 20})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.84      0.73      0.78        49\n",
      "Presence of heart disease (1)       0.72      0.83      0.77        41\n",
      "\n",
      "                  avg / total       0.79      0.78      0.78        90\n",
      "\n",
      "Misclassifications:20(22.22%),  fp:13,  fn:7\n",
      "Total Loss:48\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[36  7]\n",
      " [13 34]]\n",
      "\n",
      "\n",
      "********** Multinomial Naive Bayes (With Oversampling Class 1 of Training Set) **********\n",
      "Counter({1: 555, 0: 111})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.82      0.76      0.79        49\n",
      "Presence of heart disease (1)       0.73      0.80      0.77        41\n",
      "\n",
      "                  avg / total       0.78      0.78      0.78        90\n",
      "\n",
      "Misclassifications:20(22.22%),  fp:12,  fn:8\n",
      "Total Loss:52\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[37  8]\n",
      " [12 33]]\n",
      "\n",
      "\n",
      "********** Multinomial Naive Bayes (With Combination: Undersampling Class 0 & Oversampling Class 1 of Training Set) **********\n",
      "Counter({1: 250, 0: 50})\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.82      0.73      0.77        49\n",
      "Presence of heart disease (1)       0.72      0.80      0.76        41\n",
      "\n",
      "                  avg / total       0.77      0.77      0.77        90\n",
      "\n",
      "Misclassifications:21(23.33%),  fp:13,  fn:8\n",
      "Total Loss:53\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[36  8]\n",
      " [13 33]]\n"
     ]
    }
   ],
   "source": [
    "# List structure to hold results of specific algorithm\n",
    "mnb_st = ['Multinomial Naive Bayes']\n",
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "rs=42\n",
    "NBalpha = 0.1\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (Without Sampling) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "print(Counter(y_train))\n",
    "#0:111, 1:98\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "mnb_st.append(cost)\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (With Undersampling Class 0 of Training Set) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "sampler = RandomUnderSampler(sampling_strategy={0:20, 1:98}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "print(Counter(y_rs))\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "mnb_st.append(cost)\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (With Oversampling Class 1 of Training Set) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "sampler = RandomOverSampler(sampling_strategy={0:111, 1:555}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "print(Counter(y_rs))\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "mnb_st.append(cost)\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (With Combination: Undersampling Class 0 & Oversampling Class 1 of Training Set) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "sampler = RandomUnderSampler(sampling_strategy={0:50, 1:98}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_train, y_train)\n",
    "sampler = RandomOverSampler(sampling_strategy={0:50, 1:250}, random_state=rs)\n",
    "X_rs, y_rs = sampler.fit_sample(X_rs, y_rs)\n",
    "print(Counter(y_rs))\n",
    "model = clf.fit(X_rs, y_rs)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "mnb_st.append(cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes Algorithm Results (Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Algorithm</th>\n",
       "      <th>No Sampling</th>\n",
       "      <th>UnderSampling</th>\n",
       "      <th>OverSampling</th>\n",
       "      <th>Combination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>74</td>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Algorithm No Sampling UnderSampling OverSampling Combination\n",
       "0  Multinomial Naive Bayes          74            48           52          53"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_st = pd.Series(mnb_st, index=columns_st)\n",
    "stdf.append(mnb_st, ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- #### __All__ 3 Stratification approaches __significantly improve__ misclassification cost on Multinomial Naive Bayes Classification Algorithm\n",
    "- #### UnderSampling approach delivers __best results__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 Stratification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Algorithm</th>\n",
       "      <th>No Sampling</th>\n",
       "      <th>UnderSampling</th>\n",
       "      <th>OverSampling</th>\n",
       "      <th>Combination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>53</td>\n",
       "      <td>36</td>\n",
       "      <td>57</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>54</td>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>74</td>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Algorithm No Sampling UnderSampling OverSampling Combination\n",
       "0            Random Forest          53            36           57          40\n",
       "1               Linear SVM          54            41           34          30\n",
       "2  Multinomial Naive Bayes          74            48           52          53"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdf = stdf.append([rf_st,lsvm_st,mnb_st], ignore_index=1)\n",
    "stdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### According to the results from 3 Classification Algorithms, shown above, using 3 different Stratification approaches, I conclude the following:\n",
    "- #### Stratification __significantly improves__ misclassification cost on all 3 Classification Algorithms\n",
    "- #### __UnderSampling__ delivers best results on 2 out of 3 Classification Algorithms (Random Forest and Multinomial Naive Bayes) with respect to misclassification cost\n",
    "- #### __OverSampling__ delivers best results on Linear SVM Classification Algorithm with respect to misclassification cost\n",
    "- #### Among the 3 different Classification Algorithms examined, __Linear SVM__ delivers the best results\n",
    "- #### The Multinomial Naive Bayes Algorithm presents __very poor performance__ even after Stratification is applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 __Example Weighting__\n",
    "#### This method assigns a certain weight to each instance in terms of its class, according to the misclassification costs, such that the learning algorithm is in favor of the class with high weight/cost. \n",
    "#### In the study Dataset misclassification cost of Class 0 (corresponds to a False Positive (fp) prediction) equals to 1 whereas misclassification cost of Class 1 (corresponds to a False Negative (fn) prediction) equals to 5. So weight=1 will be assigned to each example of Class 0 whereas weight=5 will be assigned to each example of Class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create WeightMatrix containing weights for Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros(y_train.shape[0])\n",
    "# Set weight of Class 0 examples to 1 (misclassification cost of Class 0 = 1)\n",
    "weights[np.where(y_train == 0)] = 1;\n",
    "# Set weight of Class 1 examples to 5 (misclassification cost of Class 1 = 5)\n",
    "weights[np.where(y_train == 1)] = 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame to hold results for Example Weighting techniques\n",
    "columns_w = ['Classification Algorithm', 'wo Weighting', 'with Weighting']\n",
    "wdf = pd.DataFrame(columns = columns_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********** Random Forest (Without Weights) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.80      0.84      0.82        49\n",
      "Presence of heart disease (1)       0.79      0.76      0.77        41\n",
      "\n",
      "                  avg / total       0.80      0.80      0.80        90\n",
      "\n",
      "Misclassifications:18(20.00%),  fp:8,  fn:10\n",
      "Total Loss:58\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[41 10]\n",
      " [ 8 31]]\n",
      "\n",
      "\n",
      "********** Random Forest (With Weights) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.81      0.90      0.85        49\n",
      "Presence of heart disease (1)       0.86      0.76      0.81        41\n",
      "\n",
      "                  avg / total       0.84      0.83      0.83        90\n",
      "\n",
      "Misclassifications:15(16.67%),  fp:5,  fn:10\n",
      "Total Loss:55\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[44 10]\n",
      " [ 5 31]]\n"
     ]
    }
   ],
   "source": [
    "# List structure to hold results of specific algorithm\n",
    "rf_w = ['Random Forest']\n",
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "rs=42\n",
    "ests=150\n",
    "\n",
    "print('\\n\\n********** Random Forest (Without Weights) **********')\n",
    "clf = RandomForestClassifier(n_estimators=ests, random_state=rs)\n",
    "#clf = SVC(kernel='linear', probability=False, C=1)\n",
    "#clf = DecisionTreeClassifier()\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "rf_w.append(cost)\n",
    "\n",
    "print('\\n\\n********** Random Forest (With Weights) **********')\n",
    "clf = RandomForestClassifier(n_estimators=ests, random_state=rs)\n",
    "model = clf.fit(X_train, y_train, weights)\n",
    "pred_test = clf.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "rf_w.append(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Algorithm Results (Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Algorithm</th>\n",
       "      <th>wo Weighting</th>\n",
       "      <th>with Weighting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>58</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Algorithm wo Weighting with Weighting\n",
       "0            Random Forest           58             55"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_w = pd.Series(rf_w, index=columns_w)\n",
    "wdf.append(rf_w, ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- #### Example Weighting just __slightly improves__ misclassification cost on Random Forest Classification Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Linear SVM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********** Linear SVM (Without Weights) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.82      0.92      0.87        49\n",
      "Presence of heart disease (1)       0.89      0.76      0.82        41\n",
      "\n",
      "                  avg / total       0.85      0.84      0.84        90\n",
      "\n",
      "Misclassifications:14(15.56%),  fp:4,  fn:10\n",
      "Total Loss:54\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[45 10]\n",
      " [ 4 31]]\n",
      "\n",
      "\n",
      "********** Linear SVM (With Weights) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.90      0.55      0.68        49\n",
      "Presence of heart disease (1)       0.63      0.93      0.75        41\n",
      "\n",
      "                  avg / total       0.78      0.72      0.71        90\n",
      "\n",
      "Misclassifications:25(27.78%),  fp:22,  fn:3\n",
      "Total Loss:37\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[27  3]\n",
      " [22 38]]\n"
     ]
    }
   ],
   "source": [
    "# List structure to hold results of specific algorithm\n",
    "lsvm_w = ['Linear SVM']\n",
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "\n",
    "print('\\n\\n********** Linear SVM (Without Weights) **********')\n",
    "clf = SVC(kernel='linear', probability=False, C=1)\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "lsvm_w.append(cost)\n",
    "\n",
    "print('\\n\\n********** Linear SVM (With Weights) **********')\n",
    "clf = SVC(kernel='linear', probability=False, C=1)\n",
    "model = clf.fit(X_train, y_train, weights)\n",
    "pred_test = clf.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "lsvm_w.append(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM Algorithm Results (Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Algorithm</th>\n",
       "      <th>wo Weighting</th>\n",
       "      <th>with Weighting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>54</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Algorithm wo Weighting with Weighting\n",
       "0               Linear SVM           54             37"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvm_w = pd.Series(lsvm_w, index=columns_w)\n",
    "wdf.append(lsvm_w, ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- #### Example Weighting __significantly improves__ misclassification cost on Linear SVM Classification Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Multinomial Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********** Multinomial Naive Bayes (Without Weights) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.75      0.82      0.78        49\n",
      "Presence of heart disease (1)       0.76      0.68      0.72        41\n",
      "\n",
      "                  avg / total       0.76      0.76      0.75        90\n",
      "\n",
      "Misclassifications:22(24.44%),  fp:9,  fn:13\n",
      "Total Loss:74\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[40 13]\n",
      " [ 9 28]]\n",
      "\n",
      "\n",
      "********** Multinomial Naive Bayes (With Weights) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.80      0.76      0.78        49\n",
      "Presence of heart disease (1)       0.73      0.78      0.75        41\n",
      "\n",
      "                  avg / total       0.77      0.77      0.77        90\n",
      "\n",
      "Misclassifications:21(23.33%),  fp:12,  fn:9\n",
      "Total Loss:57\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[37  9]\n",
      " [12 32]]\n"
     ]
    }
   ],
   "source": [
    "# List structure to hold results of specific algorithm\n",
    "mnb_w = ['Multinomial Naive Bayes']\n",
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "NBalpha = 0.1\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (Without Weights) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "mnb_w.append(cost)\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (With Weights) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "model = clf.fit(X_train, y_train, weights)\n",
    "pred_test = clf.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "mnb_w.append(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes Algorithm Results (Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Algorithm</th>\n",
       "      <th>wo Weighting</th>\n",
       "      <th>with Weighting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>74</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Algorithm wo Weighting with Weighting\n",
       "0  Multinomial Naive Bayes           74             57"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_w = pd.Series(mnb_w, index=columns_w)\n",
    "wdf.append(mnb_w, ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- #### Example Weighting __significantly improve__ misclassification cost on Multinomial Naive Bayes Classification Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 Example Weighting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Algorithm</th>\n",
       "      <th>wo Weighting</th>\n",
       "      <th>with Weighting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>58</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>54</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>74</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Algorithm wo Weighting with Weighting\n",
       "0            Random Forest           58             55\n",
       "1               Linear SVM           54             37\n",
       "2  Multinomial Naive Bayes           74             57"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdf = wdf.append([rf_w,lsvm_w,mnb_w], ignore_index=1)\n",
    "wdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### According to the results from 3 Classification Algorithms, shown above, using 3 different Stratification approaches, I conclude the following:\n",
    "- #### Example Weighting __significantly improves__ misclassification cost on 2 out of 3 Classification Algorithms (Linear SVM and Multinomial Naive Bayes)\n",
    "- #### Example Weighting just __slightly improves__ misclassification cost on Random Forest Classification Algorithm\n",
    "- #### Among the 3 different Classification Algorithms examined, __Linear SVM__ delivers the best results\n",
    "- #### The Multinomial Naive Bayes Algorithm presents __very poor performance__ even after Example Weighting is applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 __Roulette Sampling (Cost Proportionate Roulette Sampling, CPRS)__\n",
    "#### This technique is used if misclassification cost is example dependent. However the technique could be used to our dataset, in which cost is class dependent (seen as a more specific version of the general concept).\n",
    "#### A weight is assigned to each example, equal to their misclassification cost. Then the weights turn into probabilities by dividing each one with the total sum of weights. The result number represents the probability of each example to be selected to the new dataset.\n",
    "#### Then a new dataset is created by __sampling with replacement__ the original dataset using the calculated probabilities (which is analogous to misclassification cost of each example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we must calculate each sample's probability (sample cost/sum of all samples cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to hold examples' misclassification cost\n",
    "# Create a new cost column filled with 1s\n",
    "data['cost'] = 1\n",
    "# If examples belongs to Class 1 change cost to 5\n",
    "data['cost'][data.target==1] = 5\n",
    "\n",
    "# Create a new column to hold examples' probabilities (example cost/sum of all examples cost)\n",
    "# Sum of all examples cost\n",
    "total_cost = data['cost'].sum()\n",
    "# Calculate each example's probability\n",
    "data['probs'] = data['cost']/total_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "      <th>cost</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age  sex   cp trestbps chol fbs restecg thalach exang oldpeak slope   ca  \\\n",
       "0  63  1.0  1.0      145  233   1       2     150     0     2.3     3  0.0   \n",
       "1  67  1.0  4.0      160  286   0       2     108     1     1.5     2  3.0   \n",
       "2  67  1.0  4.0      120  229   0       2     129     1     2.6     2  2.0   \n",
       "3  37  1.0  3.0      130  250   0       0     187     0     3.5     3  0.0   \n",
       "4  41  0.0  2.0      130  204   0       2     172     0     1.4     1  0.0   \n",
       "\n",
       "  thal  target  cost     probs  \n",
       "0  6.0       0     1  0.001170  \n",
       "1  3.0       1     5  0.005848  \n",
       "2  7.0       1     5  0.005848  \n",
       "3  3.0       0     1  0.001170  \n",
       "4  3.0       0     1  0.001170  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.probs.sum())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Numpy's random.choice() function to create the new dataset, same size as the original one\n",
    "# New examples are sellected from original dataset via sampling with replacement (bagging)\n",
    "# Only examples' indices are needed in this stage\n",
    "\n",
    "# Create a list of calculated examples' probabilities\n",
    "probs = list(data['probs'])\n",
    "# Create a list of examples' indices\n",
    "samples_id = list(data.index)\n",
    "\n",
    "# Generate examples' indices of the new dataset\n",
    "new_samples_id = list(np.random.choice(samples_id,size=len(samples_id),replace=True,p=probs))\n",
    "\n",
    "# Use new examples' indices to create a Dataframe containing new dataset's examples\n",
    "data_rlt = pd.DataFrame()\n",
    "for i in new_samples_id:\n",
    "    data_rlt = data_rlt.append(data[data.index == i], ignore_index=1)\n",
    "\n",
    "# Columns 'cost' and 'probs' no needed in new dataset\n",
    "data_rlt.drop(['cost','probs'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>138</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>132</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>155</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age  sex   cp trestbps chol fbs restecg thalach exang oldpeak slope   ca  \\\n",
       "0  35  0.0  4.0      138  183   0       0     182     0     1.4     1  0.0   \n",
       "1  58  1.0  3.0      132  224   0       2     173     0     3.2     1  2.0   \n",
       "2  65  0.0  3.0      155  269   0       0     148     0     0.8     1  0.0   \n",
       "3  44  1.0  4.0      120  169   0       0     144     1     2.8     3  0.0   \n",
       "4  56  1.0  4.0      130  283   1       2     103     1     1.6     3  0.0   \n",
       "\n",
       "  thal  target  \n",
       "0  3.0       0  \n",
       "1  7.0       1  \n",
       "2  3.0       0  \n",
       "3  6.0       1  \n",
       "4  7.0       1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rlt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset contains 299 examples\n",
      "\n",
      "New dataset class distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 75, 1: 224})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Examples\n",
    "samples = data_rlt.shape[0]\n",
    "print('New dataset contains %d examples' %samples)\n",
    "\n",
    "# Distribution of target labels\n",
    "print('\\nNew dataset class distribution:')\n",
    "Counter(data_rlt.target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As show above both classes are distributed acording to their samples' probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split new dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Dependent and Independent variables\n",
    "X_rlt = data_rlt.drop('target', axis=1)\n",
    "y_rlt = data_rlt.target\n",
    "# Spliting Train and Test variables\n",
    "X_train_rlt, X_test_rlt, y_train_rlt, y_test_rlt = train_test_split(X_rlt, y_rlt, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame to hold results for Roulette technique\n",
    "columns_rlt = ['Classification Algorithm', 'No_CM', 'CM', 'No_CM-RLT', 'CM-RLT']\n",
    "rltdf = pd.DataFrame(columns = columns_rlt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********** Random Forest (No Cost Minimization) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.82      0.84      0.83        49\n",
      "Presence of heart disease (1)       0.80      0.78      0.79        41\n",
      "\n",
      "                  avg / total       0.81      0.81      0.81        90\n",
      "\n",
      "Misclassifications:17(18.89%),  fp:8,  fn:9\n",
      "Total Loss:53\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[41  9]\n",
      " [ 8 32]]\n",
      "\n",
      "\n",
      "********** Random Forest (Cost Minimization) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.95      0.43      0.59        49\n",
      "Presence of heart disease (1)       0.59      0.98      0.73        41\n",
      "\n",
      "                  avg / total       0.79      0.68      0.66        90\n",
      "\n",
      "Misclassifications:29(32.22%),  fp:28,  fn:1\n",
      "Total Loss:33\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[21  1]\n",
      " [28 40]]\n",
      "\n",
      "\n",
      "********** Random Forest (No Cost Minimization - Roulette Sampling) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.88      0.88      0.88        25\n",
      "Presence of heart disease (1)       0.95      0.95      0.95        65\n",
      "\n",
      "                  avg / total       0.93      0.93      0.93        90\n",
      "\n",
      "Misclassifications:6(6.67%),  fp:3,  fn:3\n",
      "Total Loss:18\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[22  3]\n",
      " [ 3 62]]\n",
      "\n",
      "\n",
      "********** Random Forest (Cost Minimization - Roulette Sampling) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       1.00      0.48      0.65        25\n",
      "Presence of heart disease (1)       0.83      1.00      0.91        65\n",
      "\n",
      "                  avg / total       0.88      0.86      0.84        90\n",
      "\n",
      "Misclassifications:13(14.44%),  fp:13,  fn:0\n",
      "Total Loss:13\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[12  0]\n",
      " [13 65]]\n"
     ]
    }
   ],
   "source": [
    "# List structure to hold results of specific algorithm\n",
    "rf_rlt = ['Random Forest']\n",
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "rs=42  # Random State\n",
    "ests=100  # Number of Estimators\n",
    "\n",
    "print('\\n\\n********** Random Forest (No Cost Minimization) **********')\n",
    "clf = RandomForestClassifier(random_state=rs, n_estimators=ests)\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "rf_rlt.append(cost)\n",
    "\n",
    "print('\\n\\n********** Random Forest (Cost Minimization) **********')\n",
    "clf = RandomForestClassifier(random_state=rs, n_estimators=ests)\n",
    "model = clf.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "rf_rlt.append(cost)\n",
    "\n",
    "print('\\n\\n********** Random Forest (No Cost Minimization - Roulette Sampling) **********')\n",
    "clf = RandomForestClassifier(random_state=rs, n_estimators=ests)\n",
    "model = clf.fit(X_train_rlt, y_train_rlt)\n",
    "pred_test = model.predict(X_test_rlt)\n",
    "cost = print_results(y_test_rlt,pred_test,target_names,cost_matrix)\n",
    "rf_rlt.append(cost)\n",
    "\n",
    "print('\\n\\n********** Random Forest (Cost Minimization - Roulette Sampling) **********')\n",
    "clf = RandomForestClassifier(random_state=rs, n_estimators=ests)\n",
    "model = clf.fit(X_train_rlt, y_train_rlt)\n",
    "prob_test = model.predict_proba(X_test_rlt)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test_rlt,pred_test,target_names,cost_matrix)\n",
    "rf_rlt.append(cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Algorithm Results (Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Algorithm</th>\n",
       "      <th>No_CM</th>\n",
       "      <th>CM</th>\n",
       "      <th>No_CM-RLT</th>\n",
       "      <th>CM-RLT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>53</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Algorithm No_CM  CM No_CM-RLT CM-RLT\n",
       "0            Random Forest    53  33        18     13"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rlt = pd.Series(rf_rlt, index=columns_rlt)\n",
    "rltdf.append(rf_rlt, ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- #### As already shown on Probability Calibration technique, Cost Minimization __significantly improves__ misclassification cost on Random Forest Classification Algorithm\n",
    "- #### Roulette Sampling __significantly improves__ algorithm's performance even if no Cost Minimization is applied\n",
    "- #### Combination of Cost Minimization and Roulette Sampling delivers the best results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Linear SVM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********** Linear SVM (No Cost Minimization) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.82      0.92      0.87        49\n",
      "Presence of heart disease (1)       0.89      0.76      0.82        41\n",
      "\n",
      "                  avg / total       0.85      0.84      0.84        90\n",
      "\n",
      "Misclassifications:14(15.56%),  fp:4,  fn:10\n",
      "Total Loss:54\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[45 10]\n",
      " [ 4 31]]\n",
      "\n",
      "\n",
      "********** Linear SVM (Cost Minimization) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.93      0.55      0.69        49\n",
      "Presence of heart disease (1)       0.64      0.95      0.76        41\n",
      "\n",
      "                  avg / total       0.80      0.73      0.73        90\n",
      "\n",
      "Misclassifications:24(26.67%),  fp:22,  fn:2\n",
      "Total Loss:32\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[27  2]\n",
      " [22 39]]\n",
      "\n",
      "\n",
      "********** Linear SVM (No Cost Minimization - Roulette Sampling) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.90      0.72      0.80        25\n",
      "Presence of heart disease (1)       0.90      0.97      0.93        65\n",
      "\n",
      "                  avg / total       0.90      0.90      0.90        90\n",
      "\n",
      "Misclassifications:9(10.00%),  fp:7,  fn:2\n",
      "Total Loss:17\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[18  2]\n",
      " [ 7 63]]\n",
      "\n",
      "\n",
      "********** Linear SVM (Cost Minimization - Roulette Sampling) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       1.00      0.28      0.44        25\n",
      "Presence of heart disease (1)       0.78      1.00      0.88        65\n",
      "\n",
      "                  avg / total       0.84      0.80      0.76        90\n",
      "\n",
      "Misclassifications:18(20.00%),  fp:18,  fn:0\n",
      "Total Loss:18\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[ 7  0]\n",
      " [18 65]]\n"
     ]
    }
   ],
   "source": [
    "# List structure to hold results of specific algorithm\n",
    "lsvm_rlt = ['Linear SVM']\n",
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "\n",
    "print('\\n\\n********** Linear SVM (No Cost Minimization) **********')\n",
    "clf = SVC(kernel='linear', probability=True, C=1)\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "lsvm_rlt.append(cost)\n",
    "\n",
    "print('\\n\\n********** Linear SVM (Cost Minimization) **********')\n",
    "clf = SVC(kernel='linear', probability=True, C=1)\n",
    "model = clf.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "lsvm_rlt.append(cost)\n",
    "\n",
    "print('\\n\\n********** Linear SVM (No Cost Minimization - Roulette Sampling) **********')\n",
    "clf = SVC(kernel='linear', probability=True, C=1)\n",
    "model = clf.fit(X_train_rlt, y_train_rlt)\n",
    "pred_test = model.predict(X_test_rlt)\n",
    "cost = print_results(y_test_rlt,pred_test,target_names,cost_matrix)\n",
    "lsvm_rlt.append(cost)\n",
    "\n",
    "print('\\n\\n********** Linear SVM (Cost Minimization - Roulette Sampling) **********')\n",
    "clf = SVC(kernel='linear', probability=True, C=1)\n",
    "model = clf.fit(X_train_rlt, y_train_rlt)\n",
    "prob_test = model.predict_proba(X_test_rlt)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test_rlt,pred_test,target_names,cost_matrix)\n",
    "lsvm_rlt.append(cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM Algorithm Results (Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Algorithm</th>\n",
       "      <th>No_CM</th>\n",
       "      <th>CM</th>\n",
       "      <th>No_CM-RLT</th>\n",
       "      <th>CM-RLT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>54</td>\n",
       "      <td>32</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Algorithm No_CM  CM No_CM-RLT CM-RLT\n",
       "0               Linear SVM    54  32        17     18"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvm_rlt = pd.Series(lsvm_rlt, index=columns_rlt)\n",
    "rltdf.append(lsvm_rlt, ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- #### As already shown on Probability Calibration technique, Cost Minimization __significantly improves__ misclassification cost on Linear SVM Classification Algorithm\n",
    "- #### Roulette Sampling __significantly improves__ algorithm's performance even if no Cost Minimization is applied\n",
    "- #### Combination of Cost Minimization and Roulette Sampling delivers the best results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 Multinomial Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********** Multinomial Naive Bayes (No Cost Minimization) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.75      0.82      0.78        49\n",
      "Presence of heart disease (1)       0.76      0.68      0.72        41\n",
      "\n",
      "                  avg / total       0.76      0.76      0.75        90\n",
      "\n",
      "Misclassifications:22(24.44%),  fp:9,  fn:13\n",
      "Total Loss:74\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[40 13]\n",
      " [ 9 28]]\n",
      "\n",
      "\n",
      "********** Multinomial Naive Bayes (Cost Minimization) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.80      0.76      0.78        49\n",
      "Presence of heart disease (1)       0.73      0.78      0.75        41\n",
      "\n",
      "                  avg / total       0.77      0.77      0.77        90\n",
      "\n",
      "Misclassifications:21(23.33%),  fp:12,  fn:9\n",
      "Total Loss:57\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[37  9]\n",
      " [12 32]]\n",
      "\n",
      "\n",
      "********** Multinomial Naive Bayes (No Cost Minimization - Roulette Sampling) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.72      0.84      0.78        25\n",
      "Presence of heart disease (1)       0.93      0.88      0.90        65\n",
      "\n",
      "                  avg / total       0.88      0.87      0.87        90\n",
      "\n",
      "Misclassifications:12(13.33%),  fp:4,  fn:8\n",
      "Total Loss:44\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[21  8]\n",
      " [ 4 57]]\n",
      "\n",
      "\n",
      "********** Multinomial Naive Bayes (Cost Minimization - Roulette Sampling) **********\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      " Absence of heart disease (0)       0.86      0.76      0.81        25\n",
      "Presence of heart disease (1)       0.91      0.95      0.93        65\n",
      "\n",
      "                  avg / total       0.90      0.90      0.90        90\n",
      "\n",
      "Misclassifications:9(10.00%),  fp:6,  fn:3\n",
      "Total Loss:21\n",
      "\n",
      "Confusion Matrix (rows:predictions, columns:true values):\n",
      "[[19  3]\n",
      " [ 6 62]]\n"
     ]
    }
   ],
   "source": [
    "# List structure to hold results of specific algorithm\n",
    "mnb_rlt = ['Multinomial Naive Bayes']\n",
    "\n",
    "target_names = ['Absence of heart disease (0)','Presence of heart disease (1)']\n",
    "NBalpha = 0.1\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (No Cost Minimization) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "model = clf.fit(X_train, y_train)\n",
    "pred_test = model.predict(X_test)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "mnb_rlt.append(cost)\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (Cost Minimization) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "model = clf.fit(X_train, y_train)\n",
    "prob_test = model.predict_proba(X_test)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test,pred_test,target_names,cost_matrix)\n",
    "mnb_rlt.append(cost)\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (No Cost Minimization - Roulette Sampling) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "model = clf.fit(X_train_rlt, y_train_rlt)\n",
    "pred_test = model.predict(X_test_rlt)\n",
    "cost = print_results(y_test_rlt,pred_test,target_names,cost_matrix)\n",
    "mnb_rlt.append(cost)\n",
    "\n",
    "print('\\n\\n********** Multinomial Naive Bayes (Cost Minimization - Roulette Sampling) **********')\n",
    "clf = MultinomialNB(alpha = NBalpha)\n",
    "model = clf.fit(X_train_rlt, y_train_rlt)\n",
    "prob_test = model.predict_proba(X_test_rlt)\n",
    "bmr = BayesMinimumRiskClassifier(calibration=False)\n",
    "pred_test = bmr.predict(prob_test, cost_matrix)\n",
    "cost = print_results(y_test_rlt,pred_test,target_names,cost_matrix)\n",
    "mnb_rlt.append(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes Algorithm Results (Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Algorithm</th>\n",
       "      <th>No_CM</th>\n",
       "      <th>CM</th>\n",
       "      <th>No_CM-RLT</th>\n",
       "      <th>CM-RLT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>74</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Algorithm No_CM  CM No_CM-RLT CM-RLT\n",
       "0  Multinomial Naive Bayes    74  57        44     21"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_rlt = pd.Series(mnb_rlt, index=columns_rlt)\n",
    "rltdf.append(mnb_rlt, ignore_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- #### As already shown on Probability Calibration technique, Cost Minimization __significantly improves__ misclassification cost on Random Forest Classification Algorithm\n",
    "- #### Roulette Sampling __slightly improves__ algorithm's performance even if no Cost Minimization is applied\n",
    "- #### Combination of Cost Minimization and Roulette Sampling delivers the best results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.4 Roulette Sampling Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Algorithm</th>\n",
       "      <th>No_CM</th>\n",
       "      <th>CM</th>\n",
       "      <th>No_CM-RLT</th>\n",
       "      <th>CM-RLT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>53</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>54</td>\n",
       "      <td>32</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>74</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Algorithm No_CM  CM No_CM-RLT CM-RLT\n",
       "0            Random Forest    53  33        18     13\n",
       "1               Linear SVM    54  32        17     18\n",
       "2  Multinomial Naive Bayes    74  57        44     21"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rltdf = rltdf.append([rf_rlt,lsvm_rlt,mnb_rlt], ignore_index=1)\n",
    "rltdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### According to the results from 3 Classification Algorithms, shown above, using Roulette Sampling technique, I conclude the following:\n",
    "- #### Cost Minimization __significantly improves__ misclassification cost on all 3 Classification Algorithms\n",
    "- #### Roulette Sampling __significantly improves__ all 3 algorithms' performance even if no Cost Minimization is applied\n",
    "- #### Among the 4 different techniques used, __combination__ of Cost Minimization and Roulette Sampling delivers the __best results__ on all 3 algorithms\n",
    "- #### Among the 3 different Classification Algorithms examined, __Random Forest__ and __Linear SVM__ deliver the best results when combination of Cost Minimization and Roulette Sampling is applied\n",
    "- #### The Multinomial Naive Bayes Algorithm presents __very poor performance__ even if Cost Minimization is applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. __Total Results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t1. Probability Calibration Results:\n",
      "  Classification Algorithm No CM CM-No Cal CM-Costcla CM-Sigmoid CM-Isotonic\n",
      "0            Random Forest    53        33         76         34          25\n",
      "1               Linear SVM    54        28         34         33          29\n",
      "2  Multinomial Naive Bayes    74        57         37         49          35\n",
      "\n",
      "\n",
      "\t2. Stratification (Rebalancing) Results:\n",
      "  Classification Algorithm No Sampling UnderSampling OverSampling Combination\n",
      "0            Random Forest          53            36           57          40\n",
      "1               Linear SVM          54            41           34          30\n",
      "2  Multinomial Naive Bayes          74            48           52          53\n",
      "\n",
      "\n",
      "\t3. Weighting Results:\n",
      "  Classification Algorithm wo Weighting with Weighting\n",
      "0            Random Forest           58             55\n",
      "1               Linear SVM           54             37\n",
      "2  Multinomial Naive Bayes           74             57\n",
      "\n",
      "\n",
      "\t4. Roulette Sampling Results:\n",
      "  Classification Algorithm No_CM  CM No_CM-RLT CM-RLT\n",
      "0            Random Forest    53  33        18     13\n",
      "1               Linear SVM    54  32        17     18\n",
      "2  Multinomial Naive Bayes    74  57        44     21\n"
     ]
    }
   ],
   "source": [
    "print('\\t1. Probability Calibration Results:')\n",
    "print(prdf)\n",
    "print('\\n\\n\\t2. Stratification (Rebalancing) Results:')\n",
    "print(stdf)\n",
    "print('\\n\\n\\t3. Weighting Results:')\n",
    "print(wdf)\n",
    "print('\\n\\n\\t4. Roulette Sampling Results:')\n",
    "print(rltdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### According to total results shown above, from 4 different Cost-Sensitive Techniques, applied on 3 different Classification Algorithms, I conclude the following:\n",
    "- #### All 4 Cost-Sensitive Techniques __significantly improve__ misclassification cost on all 3 Classification Algorithms\n",
    "- #### When applied, Cost Minimization __significantly improves__ misclassification cost on all 3 Classification Algorithms\n",
    "- #### Regardless of the Classification Algorithm used, __Roulette Sampling__ has always shown the best results, especially when combined with Cost Minimization, followed by Probability Calibration, Stratification and finally Weighting\n",
    "- #### Among the 3 different Classification Algorithms examined:\n",
    "    - #### __Random Forest__ delivered the best results on Probability Calibration and Roulette Sampling Techniques\n",
    "    - #### __Linear SVM__ delivered the best results on Stratification and Weighting Techniques\n",
    "    - #### __Multinomial Naive Bayes__ constantly delivered the worst results regardless of the Cost-Sensitive Technique applied\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
