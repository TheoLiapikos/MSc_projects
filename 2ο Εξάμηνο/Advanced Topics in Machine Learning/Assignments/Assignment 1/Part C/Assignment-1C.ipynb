{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://www.auth.gr/sites/default/files/banner-horizontal-282x100.png)\n",
    "# Advanced Topics in Machine Learning - Assignment 1 - Part C\n",
    "\n",
    "\n",
    "## Class Imbalanced Dataset\n",
    "\n",
    "#### Useful library documentation, references, and resources used on Assignment:\n",
    "\n",
    "* Scikit-learn ML library (aka *sklearn*): <http://scikit-learn.org/stable/documentation.html>\n",
    "* Imbalanced Datasets in Machine Learning :https://github.com/scikit-learn-contrib/imbalanced-learn\n",
    "* Random Forest Classifier: <https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html>\n",
    "* Linear Support Vector Classifier: <https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html>\n",
    "* Multinomial Naive Bayes Classifier: <https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html>\n",
    "* Probability Calibration of Classifiers: <https://scikit-learn.org/stable/modules/calibration.html>\n",
    "* Model evaluation: quantifying the quality of predictions: <https://scikit-learn.org/stable/modules/model_evaluation.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wqbhrp28kt0D"
   },
   "source": [
    "#### Instructions about Dataset:\n",
    "In order to run the whole script you have first to download the dataset from the following link. \n",
    "* Credit card fraud : <https://www.kaggle.com/mlg-ulb/creditcardfraud>\n",
    "After downloading it place it in your Desktop folder or wherever you want and be sure to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit card dataset loaded.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing, datasets, model_selection, metrics, svm, naive_bayes\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_validate\n",
    "from imblearn.datasets import make_imbalance\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.combine import  SMOTETomek \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Read and print the dataset\n",
    "\n",
    "myData = pd.read_csv(r'C:/Users/raina/Desktop/creditcard.csv')\n",
    "print(\"Credit card dataset loaded.\")\n",
    "myData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wqbhrp28kt0D"
   },
   "source": [
    "#### Check if the dataset is unbalanced:\n",
    "We can clearly see that our dataset is imbalanced. In 0 class which represent the legal transactions there are 284315 samples and in 1 class, which represents fraud transactions there are only 492 transactions. This make sense because most of people do legal transactions and only a small number of them try to make a fraud transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if the dataset is really imbalanced\n",
    "\n",
    "count = pd.value_counts(myData['Class'], sort = True).sort_index()\n",
    "count.plot(kind = 'bar')\n",
    "count\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wqbhrp28kt0D"
   },
   "source": [
    "#### Drop time and split dataset:\n",
    "Time cells doesn't play important role in our case so we will drop them out. After doing it we have to split our dataset into train set and test set. Then we normalize all values [0,1] in order to have better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the class Time because it doesn't play important role\n",
    "\n",
    "myData = myData.drop(['Time'],axis=1)\n",
    "\n",
    "# Collect the values from cells and split the data into train set and test set\n",
    "\n",
    "X = myData.iloc[:,0:29].values\n",
    "y = myData.iloc[:,-1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, random_state=42)\n",
    "\n",
    "minMaxScaler = preprocessing.MinMaxScaler()\n",
    "X = minMaxScaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EASY ENSEMBLE\n",
    "\n",
    "#### Try some methods to fix the problem of imbalance\n",
    "In Easy Ensemble we will take randomly some samples without replacement from both majority and minority class. We will take the same number of samples from each class in order to have balance. We will train a boosting model and we will do this multiple time. After doing this we will combine the results with voting. In next lines we see the difference between easy ensemble and other algorithms. It is not a clever idea, using accuracy and balanced accuracy as evaluation metrics. We see that with our imbalanced dataset the results are at 1 because the difference between fraud and legal transactions are huge. Accuracy will have high results, since it looks only the correct predictions and it doesn't take into account how many mistakes the algorithm made. So, we should try some other metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Random Forest *****\n",
      "accuracy: 1.00 (+/- 0.00)\n",
      "balanced_accuracy: 0.86 (+/- 0.04)\n",
      "***** Linear SVM *****\n",
      "accuracy: 1.00 (+/- 0.00)\n",
      "balanced_accuracy: 0.86 (+/- 0.06)\n",
      "***** Naive Bayes *****\n",
      "accuracy: 1.00 (+/- 0.00)\n",
      "balanced_accuracy: 0.50 (+/- 0.00)\n",
      "***** Easy Ensemble *****\n",
      "accuracy: 0.97 (+/- 0.01)\n",
      "balanced_accuracy: 0.94 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "scoring = ['accuracy', 'balanced_accuracy']\n",
    "\n",
    "algs = []\n",
    "\n",
    "# First check three algorithms : Random forest, Linear SVM and Naive Bayes. Then check the Easy Ensemble.\n",
    "\n",
    "clfRandomForest = RandomForestClassifier(random_state=42, n_estimators=10)\n",
    "algs.append([clfRandomForest, \"***** Random Forest *****\"])\n",
    "\n",
    "clfSVM = SVC(kernel='linear', probability=True, C=1)\n",
    "algs.append([clfSVM, \"***** Linear SVM *****\"])\n",
    "\n",
    "clfNB = MultinomialNB(alpha = 0.1)\n",
    "algs.append([clfNB, \"***** Naive Bayes *****\"])\n",
    "\n",
    "\n",
    "ee = EasyEnsembleClassifier()\n",
    "algs.append([ee, \"***** Easy Ensemble *****\"])\n",
    "\n",
    "for c, d in algs:\n",
    "    print(d)\n",
    "    scores = cross_validate(c, X, y, scoring=scoring, cv=3, return_train_score=False)\n",
    "    for s in scoring:\n",
    "        print(\"%s: %0.2f (+/- %0.2f)\" % (s, scores[\"test_\" + s].mean(), scores[\"test_\" + s].std()))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve\n",
    "One good metric for imbalanced datasets is the Receiver Operating Characteristic, we use bellow. We test it in Easy Ensemble to check its results, which are very good. We also use a specified report for imbalance datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9862\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Easy Ensemble *****\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.96      0.93      0.98      0.94      0.89     71089\n",
      "          1       0.03      0.93      0.96      0.06      0.94      0.89       113\n",
      "\n",
      "avg / total       1.00      0.96      0.93      0.98      0.94      0.89     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ee = EasyEnsembleClassifier()\n",
    "y_score = ee.fit(X_train, y_train).predict_proba(X_test)\n",
    "preds = y_score[:,1]# EASY ENSEMBLE\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"%.4f\" %(roc_auc))\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %.4f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "# Easy ensemble\n",
    "\n",
    "ee = EasyEnsembleClassifier()\n",
    "ee.fit(X_train, y_train)\n",
    "\n",
    "# Classify and report the results\n",
    "\n",
    "print(\"***** Easy Ensemble *****\")\n",
    "print(classification_report_imbalanced(y_test, ee.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wqbhrp28kt0D"
   },
   "source": [
    "# NearMiss\n",
    "#### Check standalone algorithms and compined with NearMiss:\n",
    "Bellow section is about checking algorithms with different metrics than before. We also try to compine these algorithms with NearMiss method. In this method we sellect majority class examples which have the smallest average distance to the three closest minority class examples. The metrics bellow are better for imbalanced datasets and should be used in such cases. Naive Bayes compined with NearMiss seems to have the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Random Forest *****\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      1.00      0.19      1.00      0.44      0.21     71089\n",
      "          1       0.96      0.19      1.00      0.32      0.44      0.18       113\n",
      "\n",
      "avg / total       1.00      1.00      0.20      1.00      0.44      0.21     71202\n",
      "\n",
      "***** Linear SVM *****\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      1.00      0.60      1.00      0.78      0.63     71089\n",
      "          1       0.84      0.60      1.00      0.70      0.78      0.58       113\n",
      "\n",
      "avg / total       1.00      1.00      0.60      1.00      0.78      0.63     71202\n",
      "\n",
      "***** Naive Bayes *****\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      1.00      0.00      1.00      0.00      0.00     71089\n",
      "          1       0.00      0.00      1.00      0.00      0.00      0.00       113\n",
      "\n",
      "avg / total       1.00      1.00      0.00      1.00      0.00      0.00     71202\n",
      "\n",
      "***** Random Forest + NearMiss *****\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.30      0.90      0.47      0.52      0.26     71089\n",
      "          1       0.00      0.90      0.30      0.00      0.52      0.29       113\n",
      "\n",
      "avg / total       1.00      0.30      0.90      0.46      0.52      0.26     71202\n",
      "\n",
      "***** Linear SVM + NearMiss *****\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      1.00      0.25      1.00      0.50      0.27     71089\n",
      "          1       0.76      0.25      1.00      0.37      0.50      0.23       113\n",
      "\n",
      "avg / total       1.00      1.00      0.25      1.00      0.50      0.27     71202\n",
      "\n",
      "***** Naive Bayes + NearMiss *****\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      1.00      0.78      1.00      0.88      0.80     71089\n",
      "          1       0.60      0.78      1.00      0.68      0.88      0.76       113\n",
      "\n",
      "avg / total       1.00      1.00      0.78      1.00      0.88      0.80     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalize the X between [0,1] \n",
    "\n",
    "X_train = minMaxScaler.fit_transform(X_train)\n",
    "X_test = minMaxScaler.fit_transform(X_test)\n",
    "\n",
    "\n",
    "# Create a pipeline\n",
    "\n",
    "pipeline = make_pipeline(RandomForestClassifier(random_state=42, n_estimators=10))\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Classify and report the results\n",
    "\n",
    "print(\"***** Random Forest *****\")\n",
    "print(classification_report_imbalanced(y_test, pipeline.predict(X_test)))\n",
    "\n",
    "# Create a pipeline\n",
    "\n",
    "pipeline = make_pipeline(SVC(kernel='linear', probability=True, C=1))\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Classify and report the results\n",
    "\n",
    "print(\"***** Linear SVM *****\")\n",
    "print(classification_report_imbalanced(y_test, pipeline.predict(X_test)))\n",
    "\n",
    "# Create a pipeline\n",
    "\n",
    "pipeline = make_pipeline(MultinomialNB(alpha = 0.1))\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Classify and report the results\n",
    "\n",
    "print(\"***** Naive Bayes *****\")\n",
    "print(classification_report_imbalanced(y_test, pipeline.predict(X_test)))\n",
    "\n",
    "# Create a pipeline\n",
    "\n",
    "pipeline = make_pipeline(NearMiss(version=1, random_state=42),\n",
    "                         RandomForestClassifier(random_state=42, n_estimators=10))\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Classify and report the results\n",
    "\n",
    "print(\"***** Random Forest + NearMiss *****\")\n",
    "print(classification_report_imbalanced(y_test, pipeline.predict(X_test)))\n",
    "\n",
    "# Create a pipeline\n",
    "\n",
    "pipeline = make_pipeline(NearMiss(version=2, random_state=42),\n",
    "                         SVC(kernel='linear', probability=True, C=1))\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Classify and report the results\n",
    "\n",
    "print(\"***** Linear SVM + NearMiss *****\")\n",
    "print(classification_report_imbalanced(y_test, pipeline.predict(X_test)))\n",
    "\n",
    "# Create a pipeline\n",
    "\n",
    "pipeline = make_pipeline(NearMiss(version=3, random_state=42),\n",
    "                         MultinomialNB(alpha = 0.1))\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Classify and report the results\n",
    "\n",
    "print(\"***** Naive Bayes + NearMiss *****\")\n",
    "print(classification_report_imbalanced(y_test, pipeline.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wqbhrp28kt0D"
   },
   "source": [
    "# SMOTE\n",
    "\n",
    "In Synthetic Minority Over-Sampling TEchnique we first find the k nearest neighbors which belong to the minority class and then we randomly select one or more of them. After doing that we make a synthesis of a new example. Bellow we check the data before the apply of the algorithm with fraud transactions being at 0.17% of total transactions. After applying the algorithm we see that they are totally balanced at 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 28431, 1: 49})\n",
      "Percentage of fraud counts in original dataset:0.1727485630620034%\n",
      "Percentage of fraud counts in the new data:50.0%\n"
     ]
    }
   ],
   "source": [
    "# Original Dataset : 284315 Non fraud, 492 Fraud\n",
    "# Sampled Dataset : 28431 Non fraud, 49 Fraud\n",
    "# We use a sample of the original\n",
    "# dataset because if we use the whole dataset running time will increase very much.\n",
    "\n",
    "X, y = make_imbalance(X,y, \n",
    "    sampling_strategy={0: 28431, 1: 49},\n",
    "    random_state=42)\n",
    "print(Counter(y))\n",
    "\n",
    "# Apply SMOTE with Over Sampling to create synthetic observations from minority class\n",
    "\n",
    "sm = SMOTE(ratio='auto',kind='regular')\n",
    "X_train,y_train = sm.fit_sample(X,y)\n",
    "\n",
    "# Percentage of fraudlent records in original data\n",
    "\n",
    "No_fraud_counts = len(myData[myData['Class']==0])\n",
    "Fraud_counts = len(myData[myData['Class']==1])\n",
    "print('Percentage of fraud counts in original dataset:{}%'.format((Fraud_counts*100)/(No_fraud_counts+Fraud_counts)))\n",
    "\n",
    "#Percentage of fraudlent records in sampled data\n",
    "\n",
    "Sampled_data_no_fraud_counts = len(y_train[y_train==0])\n",
    "Sampled_data_fraud_counts = len(y_train[y_train==1])\n",
    "print('Percentage of fraud counts in the new data:{}%'.format((Sampled_data_fraud_counts*100)/(Sampled_data_no_fraud_counts+Sampled_data_fraud_counts)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wqbhrp28kt0D"
   },
   "source": [
    "Check Random Forest, Linear SVM and Naive Bayes after making our dataset balanced with SMOTE. Then we will use the appropriate metrics to see our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Random Forest *****\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      1.00      0.23      1.00      0.48      0.25     71089\n",
      "          1       0.81      0.23      1.00      0.36      0.48      0.21       113\n",
      "\n",
      "avg / total       1.00      1.00      0.23      1.00      0.48      0.25     71202\n",
      "\n",
      "***** Linear SVM *****\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      1.00      0.57      1.00      0.75      0.59     71089\n",
      "          1       0.74      0.57      1.00      0.64      0.75      0.54       113\n",
      "\n",
      "avg / total       1.00      1.00      0.57      1.00      0.75      0.59     71202\n",
      "\n",
      "***** Naive Bayes *****\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      1.00      0.66      1.00      0.81      0.69     71089\n",
      "          1       0.78      0.66      1.00      0.72      0.81      0.64       113\n",
      "\n",
      "avg / total       1.00      1.00      0.66      1.00      0.81      0.69     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clfRandomForest = RandomForestClassifier(random_state=42, n_estimators=10)\n",
    "clfRandomForest.fit(X_train, y_train)\n",
    "print(\"***** Random Forest *****\")\n",
    "print(classification_report_imbalanced(y_test, clfRandomForest.predict(X_test)))\n",
    "\n",
    "clfSVM = SVC(kernel='linear', probability=True, C=1)\n",
    "clfSVM.fit(X_train, y_train)\n",
    "print(\"***** Linear SVM *****\")\n",
    "print(classification_report_imbalanced(y_test, clfSVM.predict(X_test)))\n",
    "\n",
    "clfNB = MultinomialNB(alpha = 0.1)\n",
    "clfNB.fit(X_train, y_train)\n",
    "print(\"***** Naive Bayes *****\")\n",
    "print(classification_report_imbalanced(y_test, clfNB.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE WITH TOMEK LINKS\n",
    "A Tomekâ€™s link exist if the two samples are the nearest neighbors of each other. If one of them is noise or both are near a hyperplane which is seperating the classes we remove them. As before we check our dataset which have 0.17% of fraud transactions before the apply and after that it has 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in original data:28480\n",
      "Percentage of fraud counts in original dataset:0.1727485630620034%\n",
      "Percentage of fraud counts in the new data:50.0%\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE with Tomek Links to create synthetic observations from minority class\n",
    "\n",
    "ee = SMOTETomek()\n",
    "X_train,y_train  = ee.fit_sample(X,y)\n",
    "\n",
    "#Number of records in original data\n",
    "print('Total rows in original data:{}'.format(X.shape[0]))\n",
    "\n",
    "# Percentage of fraudlent records in original data\n",
    "\n",
    "No_fraud_counts = len(myData[myData['Class']==0])\n",
    "Fraud_counts = len(myData[myData['Class']==1])\n",
    "print('Percentage of fraud counts in original dataset:{}%'.format((Fraud_counts*100)/(No_fraud_counts+Fraud_counts)))\n",
    "\n",
    "#Percentage of fraudlent records in sampled data\n",
    "\n",
    "Sampled_data_no_fraud_counts = len(y_train[y_train==0])\n",
    "Sampled_data_fraud_counts = len(y_train[y_train==1])\n",
    "print('Percentage of fraud counts in the new data:{}%'.format((Sampled_data_fraud_counts*100)/(Sampled_data_no_fraud_counts+Sampled_data_fraud_counts)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wqbhrp28kt0D"
   },
   "source": [
    "Check Random Forest, Linear SVM and Naive Bayes after making our dataset balanced with SMOT. Then we will use the appropriate metrics to see our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Random Forest *****\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      1.00      0.11      1.00      0.33      0.12     71089\n",
      "          1       1.00      0.11      1.00      0.19      0.33      0.10       113\n",
      "\n",
      "avg / total       1.00      1.00      0.11      1.00      0.33      0.12     71202\n",
      "\n",
      "***** Linear SVM *****\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      1.00      0.56      1.00      0.75      0.58     71089\n",
      "          1       0.74      0.56      1.00      0.64      0.75      0.53       113\n",
      "\n",
      "avg / total       1.00      1.00      0.56      1.00      0.75      0.58     71202\n",
      "\n",
      "***** Naive Bayes *****\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      1.00      0.66      1.00      0.81      0.69     71089\n",
      "          1       0.77      0.66      1.00      0.71      0.81      0.64       113\n",
      "\n",
      "avg / total       1.00      1.00      0.66      1.00      0.81      0.69     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfRandomForest = RandomForestClassifier(random_state=42, n_estimators=10)\n",
    "clfRandomForest.fit(X_train, y_train)\n",
    "print(\"***** Random Forest *****\")\n",
    "print(classification_report_imbalanced(y_test, clfRandomForest.predict(X_test)))\n",
    "\n",
    "clfSVM = SVC(kernel='linear', probability=True, C=1)\n",
    "clfSVM.fit(X_train, y_train)\n",
    "print(\"***** Linear SVM *****\")\n",
    "print(classification_report_imbalanced(y_test, clfSVM.predict(X_test)))\n",
    "\n",
    "clfNB = MultinomialNB(alpha = 0.1)\n",
    "clfNB.fit(X_train, y_train)\n",
    "print(\"***** Naive Bayes *****\")\n",
    "print(classification_report_imbalanced(y_test, clfNB.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Top 3 results\n",
    "\n",
    "Naive Bayes seems to work better with this dataset. The best results seemed to be those which Naive Bayes and NearMiss were compined. If we check our methods, we see that NearMiss has the best results followed by Easy Ensemble and then SMOTE and SMOTE with Tomek Links. There is a little difference between the last two methods but SMOTE seems to work a little bit better than SMOTE with Tomek Links. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
